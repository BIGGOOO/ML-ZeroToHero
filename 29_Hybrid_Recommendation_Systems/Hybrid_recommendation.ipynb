{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hybrid_recommendation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHyzHlbDRaay"
      },
      "source": [
        "# **Hybrid Recommendation Systems using LightFM**\n",
        "\n",
        "A recommender system, or a recommendation system (sometimes replacing 'system' with a synonym such as platform or engine), is a subclass of information filtering system that seeks to predict the \"rating\" or \"preference\" a user would give to an item. They are primarily used in commercial applications.\n",
        "\n",
        "Recommender systems are utilized in a variety of areas and are most commonly recognized as playlist generators for video and music services like Netflix, YouTube and Spotify, product recommenders for services such as Amazon, or content recommenders for social media platforms such as Facebook and Twitter. These systems can operate using a single input, like music, or multiple inputs within and across platforms like news, books, and search queries. There are also popular recommender systems for specific topics like restaurants and online dating. Recommender systems have also been developed to explore research articles and experts, collaborators, and financial services.\n",
        "\n",
        "## **Approaches**\n",
        "\n",
        "1. Collaborative Filtering\n",
        "2. Content-based filtering\n",
        "3. Hybrid recommender systems"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUPp0-ohOHJx",
        "outputId": "1c105947-ee55-4922-d17a-8a3c5f0da5bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install zipfile36\n",
        "!pip install lightfm"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: zipfile36 in /usr/local/lib/python3.6/dist-packages (0.1.3)\n",
            "Requirement already satisfied: lightfm in /usr/local/lib/python3.6/dist-packages (1.15)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from lightfm) (1.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from lightfm) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from lightfm) (1.18.5)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->lightfm) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->lightfm) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->lightfm) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->lightfm) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4zZoYrCMERP",
        "outputId": "ff4d5cd5-2e97-49c6-dfa2-9d9ed568adfa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_B2_Pa-_Nje4"
      },
      "source": [
        "from zipfile import ZipFile \n",
        "\n",
        "path = \"/content/drive/My Drive/datasets/data-science-for-good-careervillage.zip\"\n",
        "\n",
        "# Create a ZipFile Object and losad sample.zip in it\n",
        "with ZipFile(path, 'r') as zipObj:\n",
        "   # Extract all the contents of zip file in current directory\n",
        "   zipObj.extractall()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNeIObfLNjhD"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "############################################\n",
        "# Read all our datasets and store them in pandas dataframe objects. \n",
        "############################################\n",
        "base_path = '/content/'\n",
        "df_answer_scores = pd.read_csv(\n",
        "    base_path + 'answer_scores.csv')\n",
        "\n",
        "df_answers = pd.read_csv(\n",
        "    base_path + 'answers.csv',\n",
        "    parse_dates=['answers_date_added'])\n",
        "\n",
        "df_comments = pd.read_csv(\n",
        "    base_path + 'comments.csv')\n",
        "\n",
        "df_emails = pd.read_csv(\n",
        "    base_path + 'emails.csv')\n",
        "\n",
        "df_group_memberships = pd.read_csv(\n",
        "    base_path + 'group_memberships.csv')\n",
        "\n",
        "df_groups = pd.read_csv(\n",
        "    base_path + 'groups.csv')\n",
        "\n",
        "df_matches = pd.read_csv(\n",
        "    base_path + 'matches.csv')\n",
        "\n",
        "df_professionals = pd.read_csv(\n",
        "    base_path + 'professionals.csv',\n",
        "    parse_dates=['professionals_date_joined'])\n",
        "\n",
        "df_question_scores = pd.read_csv(\n",
        "    base_path + 'question_scores.csv')\n",
        "\n",
        "df_questions = pd.read_csv(\n",
        "    base_path + 'questions.csv',\n",
        "    parse_dates=['questions_date_added'])\n",
        "\n",
        "df_school_memberships = pd.read_csv(\n",
        "    base_path + 'school_memberships.csv')\n",
        "\n",
        "df_students = pd.read_csv(\n",
        "    base_path + 'students.csv',\n",
        "    parse_dates=['students_date_joined'])\n",
        "\n",
        "df_tag_questions = pd.read_csv(\n",
        "    base_path + 'tag_questions.csv')\n",
        "\n",
        "df_tag_users = pd.read_csv(\n",
        "    base_path + 'tag_users.csv')\n",
        "\n",
        "df_tags = pd.read_csv(\n",
        "    base_path + 'tags.csv')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAt_B3QLO5QS"
      },
      "source": [
        "import lightfm.evaluation\n",
        "\n",
        "def generate_int_id(dataframe, id_col_name):\n",
        "    \"\"\"\n",
        "    Generate unique integer id for users, questions and answers\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    dataframe: Dataframe\n",
        "        Pandas Dataframe for Users or Q&A. \n",
        "    id_col_name : String \n",
        "        New integer id's column name.\n",
        "        \n",
        "    Returns\n",
        "    -------\n",
        "    Dataframe\n",
        "        Updated dataframe containing new id column \n",
        "    \"\"\"\n",
        "    new_dataframe=dataframe.assign(\n",
        "        int_id_col_name=np.arange(len(dataframe))\n",
        "        ).reset_index(drop=True)\n",
        "    return new_dataframe.rename(columns={'int_id_col_name': id_col_name})\n",
        "\n",
        "\n",
        "\n",
        "def create_features(dataframe, features_name, id_col_name):\n",
        "    \"\"\"\n",
        "    Generate features that will be ready for feeding into lightfm\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    -dataframe: Dataframe\n",
        "        Pandas Dataframe which contains features\n",
        "    -features_name : List\n",
        "        List of feature columns name avaiable in dataframe\n",
        "    -id_col_name: String\n",
        "        Column name which contains id of the question or\n",
        "        answer that the features will map to.\n",
        "        There are two possible values for this variable.\n",
        "        1. questions_id_num\n",
        "        2. professionals_id_num\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Pandas Series\n",
        "        A pandas series containing process features\n",
        "        that are ready for feed into lightfm.\n",
        "        The format of each value\n",
        "        will be (user_id, ['feature_1', 'feature_2', 'feature_3'])\n",
        "        Ex. -> (1, ['military', 'army', '5'])\n",
        "    \"\"\"\n",
        "\n",
        "    features = dataframe[features_name].apply(\n",
        "        lambda x: ','.join(x.map(str)), axis=1)\n",
        "    features = features.str.split(',')\n",
        "    features = list(zip(dataframe[id_col_name], features))\n",
        "    return features\n",
        "\n",
        "\n",
        "\n",
        "def generate_feature_list(dataframe, features_name):\n",
        "    \"\"\"\n",
        "    Generate features list for mapping \n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    dataframe: Dataframe\n",
        "        Pandas Dataframe for Users or Q&A. \n",
        "    features_name : List\n",
        "        List of feature columns name avaiable in dataframe. \n",
        "        \n",
        "    Returns\n",
        "    -------\n",
        "    List of all features for mapping \n",
        "    \"\"\"\n",
        "    features = dataframe[features_name].apply(\n",
        "        lambda x: ','.join(x.map(str)), axis=1)\n",
        "    features = features.str.split(',')\n",
        "    features = features.apply(pd.Series).stack().reset_index(drop=True)\n",
        "    return features\n",
        "\n",
        "\n",
        "def calculate_auc_score(lightfm_model, interactions_matrix, \n",
        "                        question_features, professional_features): \n",
        "    \"\"\"\n",
        "    Measure the ROC AUC metric for a model. \n",
        "    A perfect score is 1.0.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    lightfm_model: LightFM model \n",
        "        A fitted lightfm model \n",
        "    interactions_matrix : \n",
        "        A lightfm interactions matrix \n",
        "    question_features, professional_features: \n",
        "        Lightfm features \n",
        "        \n",
        "    Returns\n",
        "    -------\n",
        "    String containing AUC score \n",
        "    \"\"\"\n",
        "    score = lightfm.evaluation.auc_score( \n",
        "        lightfm_model, interactions_matrix, \n",
        "        item_features=question_features, \n",
        "        user_features=professional_features, \n",
        "        num_threads=4).mean()\n",
        "    return score"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aXmL4Z3VGK-"
      },
      "source": [
        "## **Data Preprocessing and feature creation**\n",
        "\n",
        "**Generate numeric identifier:**\n",
        "LightFM python only except numeric id. But the data CareerVillage has provided us is contains uuid for identifying users and professionals and others. In this step, I will make unique identifier for each professionals, students, questions and answers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFAI7kvkO5Sf"
      },
      "source": [
        "# generating unique integer id for users and q&a\n",
        "df_professionals = generate_int_id(df_professionals, 'professionals_id_num')\n",
        "df_students = generate_int_id(df_students, 'students_id_num')\n",
        "df_questions = generate_int_id(df_questions, 'questions_id_num')\n",
        "df_answers = generate_int_id(df_answers, 'answers_id_num')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sj7V6o9hNjjK",
        "outputId": "908652b8-fdc2-4e5a-a02a-96675c4b7e3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df_professionals.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>professionals_id</th>\n",
              "      <th>professionals_location</th>\n",
              "      <th>professionals_industry</th>\n",
              "      <th>professionals_headline</th>\n",
              "      <th>professionals_date_joined</th>\n",
              "      <th>professionals_id_num</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9ced4ce7519049c0944147afb75a8ce3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2011-10-05 20:35:19+00:00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>f718dcf6d2ec4cb0a52a9db59d7f9e67</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2011-10-05 20:49:21+00:00</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0c673e046d824ec0ad0ebe012a0673e4</td>\n",
              "      <td>New York, New York</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2011-10-18 17:31:26+00:00</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>977428d851b24183b223be0eb8619a8c</td>\n",
              "      <td>Boston, Massachusetts</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2011-11-09 20:39:29+00:00</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>e2d57e5041a44f489288397c9904c2b2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2011-12-10 22:14:44+00:00</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   professionals_id  ... professionals_id_num\n",
              "0  9ced4ce7519049c0944147afb75a8ce3  ...                    0\n",
              "1  f718dcf6d2ec4cb0a52a9db59d7f9e67  ...                    1\n",
              "2  0c673e046d824ec0ad0ebe012a0673e4  ...                    2\n",
              "3  977428d851b24183b223be0eb8619a8c  ...                    3\n",
              "4  e2d57e5041a44f489288397c9904c2b2  ...                    4\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abI9LIs6Njnj",
        "outputId": "0361f3fc-fdd3-4f78-9229-b4a498f7f1a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df_students.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>students_id</th>\n",
              "      <th>students_location</th>\n",
              "      <th>students_date_joined</th>\n",
              "      <th>students_id_num</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12a89e96755a4dba83ff03e03043d9c0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2011-12-16 14:19:24+00:00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>e37a5990fe354c60be5e87376b08d5e3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2011-12-27 03:02:44+00:00</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>12b402cceeda43dcb6e12ef9f2d221ea</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2012-01-01 05:00:00+00:00</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>a0f431fc79794edcb104f68ce55ab897</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2012-01-01 05:00:00+00:00</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>23aea4702d804bd88d1e9fb28074a1b4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2012-01-01 05:00:00+00:00</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        students_id  ... students_id_num\n",
              "0  12a89e96755a4dba83ff03e03043d9c0  ...               0\n",
              "1  e37a5990fe354c60be5e87376b08d5e3  ...               1\n",
              "2  12b402cceeda43dcb6e12ef9f2d221ea  ...               2\n",
              "3  a0f431fc79794edcb104f68ce55ab897  ...               3\n",
              "4  23aea4702d804bd88d1e9fb28074a1b4  ...               4\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20epcIY9WSo0"
      },
      "source": [
        "# **Merging Datasets:** \n",
        "This is one of the most important steps for our solution. Our professionals, students, q&a and tags are stored in seperate datasets. For purpose of model, we have to merge our datasets in very carefull way so that they are useful for our model.\n",
        "\n",
        "All tags (q&a) are stored in a separate dataset. So firstly we merge those tags with questions and answers datasets.\n",
        "Then, we merge answers with quesitons because one question can have multiple answers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18q3B6YSNjrr"
      },
      "source": [
        "###########################\n",
        "# merging dataset\n",
        "###########################\n",
        "\n",
        "# just dropna from tags \n",
        "df_tags = df_tags.dropna()\n",
        "# removing hash values.\n",
        "df_tags['tags_tag_name'] = df_tags['tags_tag_name'].str.replace('#', '')\n",
        "\n",
        "\n",
        "# merge tag_questions with tags name\n",
        "# then group all tags for each question into single rows\n",
        "df_tags_question = df_tag_questions.merge(\n",
        "    df_tags, how='inner',\n",
        "    left_on='tag_questions_tag_id', right_on='tags_tag_id')\n",
        "df_tags_question = df_tags_question.groupby(\n",
        "    ['tag_questions_question_id'])['tags_tag_name'].apply(\n",
        "        ','.join).reset_index()\n",
        "# .join is used to change seperator. seperator sy muraad 2 columns ko aapas me jis bhi seperator sy join kia ho. for e.g. space or ,\n",
        "# ak id ky jitny bhi tags thy, usny un sb ko ak hi row me merge kr dia hai with , seperator \n",
        "df_tags_question = df_tags_question.rename(columns={'tags_tag_name': 'questions_tag_name'})\n",
        "\n",
        "# merge tag_users with tags name \n",
        "# then group all tags for each user into single rows \n",
        "# after that rename the tag column name \n",
        "df_tags_pro = df_tag_users.merge(\n",
        "    df_tags, how='inner',\n",
        "    left_on='tag_users_tag_id', right_on='tags_tag_id')\n",
        "df_tags_pro = df_tags_pro.groupby(\n",
        "    ['tag_users_user_id'])['tags_tag_name'].apply(\n",
        "        ','.join).reset_index()\n",
        "# ak id sy related jitny bhi tag hain, chahy wo alag alag rows me hi q na hon, un sb ko ak row me merge kr dena. \n",
        "df_tags_pro = df_tags_pro.rename(columns={'tags_tag_name': 'professionals_tag_name'})\n",
        "\n",
        "\n",
        "# merge professionals and questions tags with main merge_dataset \n",
        "df_questions = df_questions.merge(\n",
        "    df_tags_question, how='left',\n",
        "    left_on='questions_id', right_on='tag_questions_question_id')\n",
        "df_professionals = df_professionals.merge(\n",
        "    df_tags_pro, how='left',\n",
        "    left_on='professionals_id', right_on='tag_users_user_id')\n",
        "\n",
        "# merge questions with scores \n",
        "df_questions = df_questions.merge(\n",
        "    df_question_scores, how='left',\n",
        "    left_on='questions_id', right_on='id')\n",
        "# merge questions with students \n",
        "df_questions = df_questions.merge(\n",
        "    df_students, how='left',\n",
        "    left_on='questions_author_id', right_on='students_id')\n",
        "\n",
        "\n",
        "# merge answers with questions \n",
        "# then merge professionals and questions score with that \n",
        "df_merge = df_answers.merge(\n",
        "    df_questions, how='inner',\n",
        "    left_on='answers_question_id', right_on='questions_id')\n",
        "df_merge = df_merge.merge(\n",
        "    df_professionals, how='inner',\n",
        "    left_on='answers_author_id', right_on='professionals_id')\n",
        "df_merge = df_merge.merge(\n",
        "    df_question_scores, how='inner',\n",
        "    left_on='questions_id', right_on='id')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovHIvlrRNjt9",
        "outputId": "ce29210c-6d3c-4bac-dff8-e69581e3bb66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "source": [
        "df_merge.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>answers_id</th>\n",
              "      <th>answers_author_id</th>\n",
              "      <th>answers_question_id</th>\n",
              "      <th>answers_date_added</th>\n",
              "      <th>answers_body</th>\n",
              "      <th>answers_id_num</th>\n",
              "      <th>questions_id</th>\n",
              "      <th>questions_author_id</th>\n",
              "      <th>questions_date_added</th>\n",
              "      <th>questions_title</th>\n",
              "      <th>questions_body</th>\n",
              "      <th>questions_id_num</th>\n",
              "      <th>tag_questions_question_id</th>\n",
              "      <th>questions_tag_name</th>\n",
              "      <th>id_x</th>\n",
              "      <th>score_x</th>\n",
              "      <th>students_id</th>\n",
              "      <th>students_location</th>\n",
              "      <th>students_date_joined</th>\n",
              "      <th>students_id_num</th>\n",
              "      <th>professionals_id</th>\n",
              "      <th>professionals_location</th>\n",
              "      <th>professionals_industry</th>\n",
              "      <th>professionals_headline</th>\n",
              "      <th>professionals_date_joined</th>\n",
              "      <th>professionals_id_num</th>\n",
              "      <th>tag_users_user_id</th>\n",
              "      <th>professionals_tag_name</th>\n",
              "      <th>id_y</th>\n",
              "      <th>score_y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4e5f01128cae4f6d8fd697cec5dca60c</td>\n",
              "      <td>36ff3b3666df400f956f8335cf53e09e</td>\n",
              "      <td>332a511f1569444485cf7a7a556a5e54</td>\n",
              "      <td>2016-04-29 19:40:14+00:00</td>\n",
              "      <td>&lt;p&gt;Hi!&lt;/p&gt;\\n&lt;p&gt;You are asking a very interesti...</td>\n",
              "      <td>0</td>\n",
              "      <td>332a511f1569444485cf7a7a556a5e54</td>\n",
              "      <td>8f6f374ffd834d258ab69d376dd998f5</td>\n",
              "      <td>2016-04-26 11:14:26+00:00</td>\n",
              "      <td>Teacher   career   question</td>\n",
              "      <td>What  is  a  maths  teacher?   what  is  a  ma...</td>\n",
              "      <td>0</td>\n",
              "      <td>332a511f1569444485cf7a7a556a5e54</td>\n",
              "      <td>lecture,college,professor</td>\n",
              "      <td>332a511f1569444485cf7a7a556a5e54</td>\n",
              "      <td>1.0</td>\n",
              "      <td>8f6f374ffd834d258ab69d376dd998f5</td>\n",
              "      <td>Coimbatore, Tamil Nadu, India</td>\n",
              "      <td>2016-04-22 10:07:32+00:00</td>\n",
              "      <td>6890.0</td>\n",
              "      <td>36ff3b3666df400f956f8335cf53e09e</td>\n",
              "      <td>Cleveland, Ohio</td>\n",
              "      <td>Mental Health Care</td>\n",
              "      <td>Assist with Recognizing and Developing Potential</td>\n",
              "      <td>2015-10-19 20:56:49+00:00</td>\n",
              "      <td>2410</td>\n",
              "      <td>36ff3b3666df400f956f8335cf53e09e</td>\n",
              "      <td>engineering,computer-science,science,college,e...</td>\n",
              "      <td>332a511f1569444485cf7a7a556a5e54</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>f3519ab99a1a4a13a8a9ecb814287d2a</td>\n",
              "      <td>36ff3b3666df400f956f8335cf53e09e</td>\n",
              "      <td>0f1d6a4f276c4a05878dd48e03e52289</td>\n",
              "      <td>2016-07-31 15:35:54+00:00</td>\n",
              "      <td>&lt;p&gt;Hi Rodrigo!&lt;/p&gt;\\n&lt;p&gt;The important thing to ...</td>\n",
              "      <td>11</td>\n",
              "      <td>0f1d6a4f276c4a05878dd48e03e52289</td>\n",
              "      <td>585ac233015447cc9e9a217044e515e1</td>\n",
              "      <td>2016-05-19 22:16:25+00:00</td>\n",
              "      <td>what kind of  college could i go  to for a soc...</td>\n",
              "      <td>I like soccer because i been playing sense i w...</td>\n",
              "      <td>7</td>\n",
              "      <td>0f1d6a4f276c4a05878dd48e03e52289</td>\n",
              "      <td>college,building,soccer</td>\n",
              "      <td>0f1d6a4f276c4a05878dd48e03e52289</td>\n",
              "      <td>1.0</td>\n",
              "      <td>585ac233015447cc9e9a217044e515e1</td>\n",
              "      <td>Morgan Hill, California</td>\n",
              "      <td>2016-05-19 22:08:48+00:00</td>\n",
              "      <td>10014.0</td>\n",
              "      <td>36ff3b3666df400f956f8335cf53e09e</td>\n",
              "      <td>Cleveland, Ohio</td>\n",
              "      <td>Mental Health Care</td>\n",
              "      <td>Assist with Recognizing and Developing Potential</td>\n",
              "      <td>2015-10-19 20:56:49+00:00</td>\n",
              "      <td>2410</td>\n",
              "      <td>36ff3b3666df400f956f8335cf53e09e</td>\n",
              "      <td>engineering,computer-science,science,college,e...</td>\n",
              "      <td>0f1d6a4f276c4a05878dd48e03e52289</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>825f6e316a5f48328d6f8af831df9940</td>\n",
              "      <td>36ff3b3666df400f956f8335cf53e09e</td>\n",
              "      <td>0149c6d63e214040b44d4a3789bb00ba</td>\n",
              "      <td>2018-04-15 23:08:46+00:00</td>\n",
              "      <td>&lt;p&gt;Congratulations on being interested in find...</td>\n",
              "      <td>71</td>\n",
              "      <td>0149c6d63e214040b44d4a3789bb00ba</td>\n",
              "      <td>34217a1861d640a58c85e033414cf9cb</td>\n",
              "      <td>2018-04-12 17:13:45+00:00</td>\n",
              "      <td>What is the best way to prepare for studying e...</td>\n",
              "      <td>I am interested in Computational Neuroscience,...</td>\n",
              "      <td>33</td>\n",
              "      <td>0149c6d63e214040b44d4a3789bb00ba</td>\n",
              "      <td>engineering,neuroscience,gradschool</td>\n",
              "      <td>0149c6d63e214040b44d4a3789bb00ba</td>\n",
              "      <td>2.0</td>\n",
              "      <td>34217a1861d640a58c85e033414cf9cb</td>\n",
              "      <td>Austin, Texas</td>\n",
              "      <td>2018-04-12 17:09:31+00:00</td>\n",
              "      <td>26796.0</td>\n",
              "      <td>36ff3b3666df400f956f8335cf53e09e</td>\n",
              "      <td>Cleveland, Ohio</td>\n",
              "      <td>Mental Health Care</td>\n",
              "      <td>Assist with Recognizing and Developing Potential</td>\n",
              "      <td>2015-10-19 20:56:49+00:00</td>\n",
              "      <td>2410</td>\n",
              "      <td>36ff3b3666df400f956f8335cf53e09e</td>\n",
              "      <td>engineering,computer-science,science,college,e...</td>\n",
              "      <td>0149c6d63e214040b44d4a3789bb00ba</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>fb2c794175304c4caeb55e654270421f</td>\n",
              "      <td>a32736b04c27437da3078374d47af1b1</td>\n",
              "      <td>0149c6d63e214040b44d4a3789bb00ba</td>\n",
              "      <td>2018-04-13 18:18:05+00:00</td>\n",
              "      <td>&lt;p&gt;Hi Elisabeth! &lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;If you are ...</td>\n",
              "      <td>72</td>\n",
              "      <td>0149c6d63e214040b44d4a3789bb00ba</td>\n",
              "      <td>34217a1861d640a58c85e033414cf9cb</td>\n",
              "      <td>2018-04-12 17:13:45+00:00</td>\n",
              "      <td>What is the best way to prepare for studying e...</td>\n",
              "      <td>I am interested in Computational Neuroscience,...</td>\n",
              "      <td>33</td>\n",
              "      <td>0149c6d63e214040b44d4a3789bb00ba</td>\n",
              "      <td>engineering,neuroscience,gradschool</td>\n",
              "      <td>0149c6d63e214040b44d4a3789bb00ba</td>\n",
              "      <td>2.0</td>\n",
              "      <td>34217a1861d640a58c85e033414cf9cb</td>\n",
              "      <td>Austin, Texas</td>\n",
              "      <td>2018-04-12 17:09:31+00:00</td>\n",
              "      <td>26796.0</td>\n",
              "      <td>a32736b04c27437da3078374d47af1b1</td>\n",
              "      <td>San Francisco, California</td>\n",
              "      <td>Computer Software</td>\n",
              "      <td>Product Management @ Okta</td>\n",
              "      <td>2018-04-13 17:48:09+00:00</td>\n",
              "      <td>18373</td>\n",
              "      <td>a32736b04c27437da3078374d47af1b1</td>\n",
              "      <td>computer-software</td>\n",
              "      <td>0149c6d63e214040b44d4a3789bb00ba</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>f3fc23809cda472780fc565334f35000</td>\n",
              "      <td>36ff3b3666df400f956f8335cf53e09e</td>\n",
              "      <td>acc611cfb5c44daa8a3d7d65dfffa5ff</td>\n",
              "      <td>2018-08-14 10:37:01+00:00</td>\n",
              "      <td>&lt;p&gt;The most important thing that you can do is...</td>\n",
              "      <td>102</td>\n",
              "      <td>acc611cfb5c44daa8a3d7d65dfffa5ff</td>\n",
              "      <td>5b751a8ee4a047f7a08ce9eb5e43e5a2</td>\n",
              "      <td>2018-08-14 04:49:33+00:00</td>\n",
              "      <td>How should I prepare myself for my job search ...</td>\n",
              "      <td>I am a Sociology, Political Science, and Inter...</td>\n",
              "      <td>47</td>\n",
              "      <td>acc611cfb5c44daa8a3d7d65dfffa5ff</td>\n",
              "      <td>job-search,career-choice,job,college-jobs</td>\n",
              "      <td>acc611cfb5c44daa8a3d7d65dfffa5ff</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5b751a8ee4a047f7a08ce9eb5e43e5a2</td>\n",
              "      <td>Kingston, Pennsylvania</td>\n",
              "      <td>2018-08-14 04:47:13+00:00</td>\n",
              "      <td>28533.0</td>\n",
              "      <td>36ff3b3666df400f956f8335cf53e09e</td>\n",
              "      <td>Cleveland, Ohio</td>\n",
              "      <td>Mental Health Care</td>\n",
              "      <td>Assist with Recognizing and Developing Potential</td>\n",
              "      <td>2015-10-19 20:56:49+00:00</td>\n",
              "      <td>2410</td>\n",
              "      <td>36ff3b3666df400f956f8335cf53e09e</td>\n",
              "      <td>engineering,computer-science,science,college,e...</td>\n",
              "      <td>acc611cfb5c44daa8a3d7d65dfffa5ff</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         answers_id  ... score_y\n",
              "0  4e5f01128cae4f6d8fd697cec5dca60c  ...       1\n",
              "1  f3519ab99a1a4a13a8a9ecb814287d2a  ...       1\n",
              "2  825f6e316a5f48328d6f8af831df9940  ...       2\n",
              "3  fb2c794175304c4caeb55e654270421f  ...       2\n",
              "4  f3fc23809cda472780fc565334f35000  ...       1\n",
              "\n",
              "[5 rows x 30 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1H7IDlo3QPk0"
      },
      "source": [
        "**Generate some features:** In this steps, we are going to generate some features. We are going to generate number of answers by professionals, num of answers in each question, num of tags per professionals and number of tags per question. I will not use all of these features in this model. But I will use number of answers per question for weighting our model so that our model pay less attention to those quesitons that have higher number of answers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5UhccAjN4o3"
      },
      "source": [
        "#######################\n",
        "# Generate some features for calculates weights\n",
        "# that will use with interaction matrix \n",
        "#######################\n",
        "original = df_merge.copy()\n",
        "\n",
        "original['num_of_ans_by_professional'] = original.groupby(['answers_author_id'])['questions_id'].transform('count')\n",
        "# mtlb har ak professional ny kitny no of questions ko ans kra hai.\n",
        "original['num_ans_per_ques'] = original.groupby(['questions_id'])['answers_id'].transform('count')\n",
        "# mtlb har ak swaal k kitny ans hain\n",
        "original['num_tags_professional'] = original['professionals_tag_name'].str.split(\",\").str.len()\n",
        "# here we r counting no of tags yani her professional ny kitny tags ko like ya enroll kra va hai apni profile me. \n",
        "original['num_tags_question'] = original['questions_tag_name'].str.split(\",\").str.len()\n",
        "# here we r counnting k her question k sth kitny tag hain. yani question ko post krty vkt user ny us k sth kitny tag lgaye we r counting tat.\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3TSz2X1Telr",
        "outputId": "803214e6-4fb8-47a1-c644-50b23957e0a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "source": [
        "original.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>answers_id</th>\n",
              "      <th>answers_author_id</th>\n",
              "      <th>answers_question_id</th>\n",
              "      <th>answers_date_added</th>\n",
              "      <th>answers_body</th>\n",
              "      <th>answers_id_num</th>\n",
              "      <th>questions_id</th>\n",
              "      <th>questions_author_id</th>\n",
              "      <th>questions_date_added</th>\n",
              "      <th>questions_title</th>\n",
              "      <th>questions_body</th>\n",
              "      <th>questions_id_num</th>\n",
              "      <th>tag_questions_question_id</th>\n",
              "      <th>questions_tag_name</th>\n",
              "      <th>id_x</th>\n",
              "      <th>score_x</th>\n",
              "      <th>students_id</th>\n",
              "      <th>students_location</th>\n",
              "      <th>students_date_joined</th>\n",
              "      <th>students_id_num</th>\n",
              "      <th>professionals_id</th>\n",
              "      <th>professionals_location</th>\n",
              "      <th>professionals_industry</th>\n",
              "      <th>professionals_headline</th>\n",
              "      <th>professionals_date_joined</th>\n",
              "      <th>professionals_id_num</th>\n",
              "      <th>tag_users_user_id</th>\n",
              "      <th>professionals_tag_name</th>\n",
              "      <th>id_y</th>\n",
              "      <th>score_y</th>\n",
              "      <th>num_of_ans_by_professional</th>\n",
              "      <th>num_ans_per_ques</th>\n",
              "      <th>num_tags_professional</th>\n",
              "      <th>num_tags_question</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4e5f01128cae4f6d8fd697cec5dca60c</td>\n",
              "      <td>36ff3b3666df400f956f8335cf53e09e</td>\n",
              "      <td>332a511f1569444485cf7a7a556a5e54</td>\n",
              "      <td>2016-04-29 19:40:14+00:00</td>\n",
              "      <td>&lt;p&gt;Hi!&lt;/p&gt;\\n&lt;p&gt;You are asking a very interesti...</td>\n",
              "      <td>0</td>\n",
              "      <td>332a511f1569444485cf7a7a556a5e54</td>\n",
              "      <td>8f6f374ffd834d258ab69d376dd998f5</td>\n",
              "      <td>2016-04-26 11:14:26+00:00</td>\n",
              "      <td>Teacher   career   question</td>\n",
              "      <td>What  is  a  maths  teacher?   what  is  a  ma...</td>\n",
              "      <td>0</td>\n",
              "      <td>332a511f1569444485cf7a7a556a5e54</td>\n",
              "      <td>lecture,college,professor</td>\n",
              "      <td>332a511f1569444485cf7a7a556a5e54</td>\n",
              "      <td>1.0</td>\n",
              "      <td>8f6f374ffd834d258ab69d376dd998f5</td>\n",
              "      <td>Coimbatore, Tamil Nadu, India</td>\n",
              "      <td>2016-04-22 10:07:32+00:00</td>\n",
              "      <td>6890.0</td>\n",
              "      <td>36ff3b3666df400f956f8335cf53e09e</td>\n",
              "      <td>Cleveland, Ohio</td>\n",
              "      <td>Mental Health Care</td>\n",
              "      <td>Assist with Recognizing and Developing Potential</td>\n",
              "      <td>2015-10-19 20:56:49+00:00</td>\n",
              "      <td>2410</td>\n",
              "      <td>36ff3b3666df400f956f8335cf53e09e</td>\n",
              "      <td>engineering,computer-science,science,college,e...</td>\n",
              "      <td>332a511f1569444485cf7a7a556a5e54</td>\n",
              "      <td>1</td>\n",
              "      <td>1710</td>\n",
              "      <td>1</td>\n",
              "      <td>12.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>f3519ab99a1a4a13a8a9ecb814287d2a</td>\n",
              "      <td>36ff3b3666df400f956f8335cf53e09e</td>\n",
              "      <td>0f1d6a4f276c4a05878dd48e03e52289</td>\n",
              "      <td>2016-07-31 15:35:54+00:00</td>\n",
              "      <td>&lt;p&gt;Hi Rodrigo!&lt;/p&gt;\\n&lt;p&gt;The important thing to ...</td>\n",
              "      <td>11</td>\n",
              "      <td>0f1d6a4f276c4a05878dd48e03e52289</td>\n",
              "      <td>585ac233015447cc9e9a217044e515e1</td>\n",
              "      <td>2016-05-19 22:16:25+00:00</td>\n",
              "      <td>what kind of  college could i go  to for a soc...</td>\n",
              "      <td>I like soccer because i been playing sense i w...</td>\n",
              "      <td>7</td>\n",
              "      <td>0f1d6a4f276c4a05878dd48e03e52289</td>\n",
              "      <td>college,building,soccer</td>\n",
              "      <td>0f1d6a4f276c4a05878dd48e03e52289</td>\n",
              "      <td>1.0</td>\n",
              "      <td>585ac233015447cc9e9a217044e515e1</td>\n",
              "      <td>Morgan Hill, California</td>\n",
              "      <td>2016-05-19 22:08:48+00:00</td>\n",
              "      <td>10014.0</td>\n",
              "      <td>36ff3b3666df400f956f8335cf53e09e</td>\n",
              "      <td>Cleveland, Ohio</td>\n",
              "      <td>Mental Health Care</td>\n",
              "      <td>Assist with Recognizing and Developing Potential</td>\n",
              "      <td>2015-10-19 20:56:49+00:00</td>\n",
              "      <td>2410</td>\n",
              "      <td>36ff3b3666df400f956f8335cf53e09e</td>\n",
              "      <td>engineering,computer-science,science,college,e...</td>\n",
              "      <td>0f1d6a4f276c4a05878dd48e03e52289</td>\n",
              "      <td>1</td>\n",
              "      <td>1710</td>\n",
              "      <td>1</td>\n",
              "      <td>12.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>825f6e316a5f48328d6f8af831df9940</td>\n",
              "      <td>36ff3b3666df400f956f8335cf53e09e</td>\n",
              "      <td>0149c6d63e214040b44d4a3789bb00ba</td>\n",
              "      <td>2018-04-15 23:08:46+00:00</td>\n",
              "      <td>&lt;p&gt;Congratulations on being interested in find...</td>\n",
              "      <td>71</td>\n",
              "      <td>0149c6d63e214040b44d4a3789bb00ba</td>\n",
              "      <td>34217a1861d640a58c85e033414cf9cb</td>\n",
              "      <td>2018-04-12 17:13:45+00:00</td>\n",
              "      <td>What is the best way to prepare for studying e...</td>\n",
              "      <td>I am interested in Computational Neuroscience,...</td>\n",
              "      <td>33</td>\n",
              "      <td>0149c6d63e214040b44d4a3789bb00ba</td>\n",
              "      <td>engineering,neuroscience,gradschool</td>\n",
              "      <td>0149c6d63e214040b44d4a3789bb00ba</td>\n",
              "      <td>2.0</td>\n",
              "      <td>34217a1861d640a58c85e033414cf9cb</td>\n",
              "      <td>Austin, Texas</td>\n",
              "      <td>2018-04-12 17:09:31+00:00</td>\n",
              "      <td>26796.0</td>\n",
              "      <td>36ff3b3666df400f956f8335cf53e09e</td>\n",
              "      <td>Cleveland, Ohio</td>\n",
              "      <td>Mental Health Care</td>\n",
              "      <td>Assist with Recognizing and Developing Potential</td>\n",
              "      <td>2015-10-19 20:56:49+00:00</td>\n",
              "      <td>2410</td>\n",
              "      <td>36ff3b3666df400f956f8335cf53e09e</td>\n",
              "      <td>engineering,computer-science,science,college,e...</td>\n",
              "      <td>0149c6d63e214040b44d4a3789bb00ba</td>\n",
              "      <td>2</td>\n",
              "      <td>1710</td>\n",
              "      <td>2</td>\n",
              "      <td>12.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>fb2c794175304c4caeb55e654270421f</td>\n",
              "      <td>a32736b04c27437da3078374d47af1b1</td>\n",
              "      <td>0149c6d63e214040b44d4a3789bb00ba</td>\n",
              "      <td>2018-04-13 18:18:05+00:00</td>\n",
              "      <td>&lt;p&gt;Hi Elisabeth! &lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;If you are ...</td>\n",
              "      <td>72</td>\n",
              "      <td>0149c6d63e214040b44d4a3789bb00ba</td>\n",
              "      <td>34217a1861d640a58c85e033414cf9cb</td>\n",
              "      <td>2018-04-12 17:13:45+00:00</td>\n",
              "      <td>What is the best way to prepare for studying e...</td>\n",
              "      <td>I am interested in Computational Neuroscience,...</td>\n",
              "      <td>33</td>\n",
              "      <td>0149c6d63e214040b44d4a3789bb00ba</td>\n",
              "      <td>engineering,neuroscience,gradschool</td>\n",
              "      <td>0149c6d63e214040b44d4a3789bb00ba</td>\n",
              "      <td>2.0</td>\n",
              "      <td>34217a1861d640a58c85e033414cf9cb</td>\n",
              "      <td>Austin, Texas</td>\n",
              "      <td>2018-04-12 17:09:31+00:00</td>\n",
              "      <td>26796.0</td>\n",
              "      <td>a32736b04c27437da3078374d47af1b1</td>\n",
              "      <td>San Francisco, California</td>\n",
              "      <td>Computer Software</td>\n",
              "      <td>Product Management @ Okta</td>\n",
              "      <td>2018-04-13 17:48:09+00:00</td>\n",
              "      <td>18373</td>\n",
              "      <td>a32736b04c27437da3078374d47af1b1</td>\n",
              "      <td>computer-software</td>\n",
              "      <td>0149c6d63e214040b44d4a3789bb00ba</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>f3fc23809cda472780fc565334f35000</td>\n",
              "      <td>36ff3b3666df400f956f8335cf53e09e</td>\n",
              "      <td>acc611cfb5c44daa8a3d7d65dfffa5ff</td>\n",
              "      <td>2018-08-14 10:37:01+00:00</td>\n",
              "      <td>&lt;p&gt;The most important thing that you can do is...</td>\n",
              "      <td>102</td>\n",
              "      <td>acc611cfb5c44daa8a3d7d65dfffa5ff</td>\n",
              "      <td>5b751a8ee4a047f7a08ce9eb5e43e5a2</td>\n",
              "      <td>2018-08-14 04:49:33+00:00</td>\n",
              "      <td>How should I prepare myself for my job search ...</td>\n",
              "      <td>I am a Sociology, Political Science, and Inter...</td>\n",
              "      <td>47</td>\n",
              "      <td>acc611cfb5c44daa8a3d7d65dfffa5ff</td>\n",
              "      <td>job-search,career-choice,job,college-jobs</td>\n",
              "      <td>acc611cfb5c44daa8a3d7d65dfffa5ff</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5b751a8ee4a047f7a08ce9eb5e43e5a2</td>\n",
              "      <td>Kingston, Pennsylvania</td>\n",
              "      <td>2018-08-14 04:47:13+00:00</td>\n",
              "      <td>28533.0</td>\n",
              "      <td>36ff3b3666df400f956f8335cf53e09e</td>\n",
              "      <td>Cleveland, Ohio</td>\n",
              "      <td>Mental Health Care</td>\n",
              "      <td>Assist with Recognizing and Developing Potential</td>\n",
              "      <td>2015-10-19 20:56:49+00:00</td>\n",
              "      <td>2410</td>\n",
              "      <td>36ff3b3666df400f956f8335cf53e09e</td>\n",
              "      <td>engineering,computer-science,science,college,e...</td>\n",
              "      <td>acc611cfb5c44daa8a3d7d65dfffa5ff</td>\n",
              "      <td>1</td>\n",
              "      <td>1710</td>\n",
              "      <td>1</td>\n",
              "      <td>12.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         answers_id  ... num_tags_question\n",
              "0  4e5f01128cae4f6d8fd697cec5dca60c  ...               3.0\n",
              "1  f3519ab99a1a4a13a8a9ecb814287d2a  ...               3.0\n",
              "2  825f6e316a5f48328d6f8af831df9940  ...               3.0\n",
              "3  fb2c794175304c4caeb55e654270421f  ...               3.0\n",
              "4  f3fc23809cda472780fc565334f35000  ...               4.0\n",
              "\n",
              "[5 rows x 34 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EU5hPjqYfvu",
        "outputId": "691281f7-907c-4141-9b8d-7ec4ff0db150",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"Maximum number of answer per question : \" + str(original['num_ans_per_ques'].max()))\n",
        "print(\"Maximum number of tags per professional : \" + str(original['num_tags_professional'].max()))\n",
        "print(\"Maximum number of tags per question : \" + str(original['num_tags_question'].max()))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Maximum number of answer per question : 58\n",
            "Maximum number of tags per professional : 82.0\n",
            "Maximum number of tags per question : 54.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcpIw7qjZLtV"
      },
      "source": [
        "**Merge answered questions tags with professional's tags:**\n",
        "Professionals can follow some tags. But not all professional follow tags and most especially we see from EDA that sometime professionals answers questions that is not related to their tags. For that reason, I have merge questions tags that each professional has answered with professional tags. This makes our model more robust and context aware."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Uxx8dWvYftX"
      },
      "source": [
        "########################\n",
        "# Merge professionals previous answered \n",
        "# questions tags into professionals tags \n",
        "########################\n",
        "# mtlb for e.g professional datascientist hai or usny tag bhi datascience ka like kra va hai, and then usny datascience k tags k questions ko ans kra va hai\n",
        "# to hum datascience sy relatd tamaam questions answered by tat datascientist ko merge kr dengy.\n",
        "\n",
        "# select professionals answered questions tags \n",
        "# and stored as a dataframe\n",
        "professionals_prev_ans_tags = original[['professionals_id', 'questions_tag_name']]\n",
        "# drop null values from that \n",
        "professionals_prev_ans_tags = professionals_prev_ans_tags.dropna()\n",
        "# because professsionals answers multiple questions, \n",
        "# we group all of tags of each user into single row \n",
        "professionals_prev_ans_tags = professionals_prev_ans_tags.groupby(\n",
        "    ['professionals_id'])['questions_tag_name'].apply(\n",
        "        ','.join).reset_index()\n",
        "# ak professional id ny boht sary questions ko ans kra va hai so un tamam questions k sth koi na koi tags hongy to hum un tamam tags ko jin k questions professional ny ans\n",
        "# kry hain, merge kr dengy.\n",
        "\n",
        "# drop duplicates tags from each professionals rows\n",
        "professionals_prev_ans_tags['questions_tag_name'] = (\n",
        "    professionals_prev_ans_tags['questions_tag_name'].str.split(',').apply(set).str.join(','))\n",
        "# yha par set operation lgaya jaa rha hai har row par taky duplicate tags remove ho jaen.\n",
        "\n",
        "# finally merge the dataframe with professionals dataframe \n",
        "df_professionals = df_professionals.merge(professionals_prev_ans_tags, how='left', on='professionals_id')\n",
        "\n",
        "prof_copy = df_professionals.copy()\n",
        "# join professionals tags and their answered tags \n",
        "# we replace nan values with \"\"\n",
        "prof_copy['professional_all_tags'] = (\n",
        "    prof_copy[['professionals_tag_name', 'questions_tag_name']].apply(\n",
        "        lambda x: ','.join(x.dropna()),\n",
        "        axis=1))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u23cAh3outPi",
        "outputId": "82fdd89a-0749-44c5-c893-c461c3b70ac5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "prof_copy.head()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>professionals_id</th>\n",
              "      <th>professionals_location</th>\n",
              "      <th>professionals_industry</th>\n",
              "      <th>professionals_headline</th>\n",
              "      <th>professionals_date_joined</th>\n",
              "      <th>professionals_id_num</th>\n",
              "      <th>tag_users_user_id</th>\n",
              "      <th>professionals_tag_name</th>\n",
              "      <th>questions_tag_name</th>\n",
              "      <th>professional_all_tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9ced4ce7519049c0944147afb75a8ce3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2011-10-05 20:35:19+00:00</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>resume,consulting</td>\n",
              "      <td>resume,consulting</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>f718dcf6d2ec4cb0a52a9db59d7f9e67</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2011-10-05 20:49:21+00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0c673e046d824ec0ad0ebe012a0673e4</td>\n",
              "      <td>New York, New York</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2011-10-18 17:31:26+00:00</td>\n",
              "      <td>2</td>\n",
              "      <td>0c673e046d824ec0ad0ebe012a0673e4</td>\n",
              "      <td>consulting,consulting,consulting,consulting,co...</td>\n",
              "      <td>hire,doctor,justice,detective,consulting,mecha...</td>\n",
              "      <td>consulting,consulting,consulting,consulting,co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>977428d851b24183b223be0eb8619a8c</td>\n",
              "      <td>Boston, Massachusetts</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2011-11-09 20:39:29+00:00</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>justice,detective,forensic,neurosurgeon,math,c...</td>\n",
              "      <td>justice,detective,forensic,neurosurgeon,math,c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>e2d57e5041a44f489288397c9904c2b2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2011-12-10 22:14:44+00:00</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   professionals_id  ...                              professional_all_tags\n",
              "0  9ced4ce7519049c0944147afb75a8ce3  ...                                  resume,consulting\n",
              "1  f718dcf6d2ec4cb0a52a9db59d7f9e67  ...                                                   \n",
              "2  0c673e046d824ec0ad0ebe012a0673e4  ...  consulting,consulting,consulting,consulting,co...\n",
              "3  977428d851b24183b223be0eb8619a8c  ...  justice,detective,forensic,neurosurgeon,math,c...\n",
              "4  e2d57e5041a44f489288397c9904c2b2  ...                                                   \n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIZ-MfbUuRxG"
      },
      "source": [
        "**Handling null and duplicates values:** Now we want clean our data a little bit. We will handle null and duplicate values. Because if we don't remove that they will cause error and wrong prediction. Also, we will replace null values with generic name or value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBQ8S_EGuK3L"
      },
      "source": [
        "# handling null values \n",
        "df_questions['score'] = df_questions['score'].fillna(0)\n",
        "df_questions['score'] = df_questions['score'].astype(int)\n",
        "df_questions['questions_tag_name'] = df_questions['questions_tag_name'].fillna('No Tag')\n",
        "# remove duplicates tags from each questions \n",
        "df_questions['questions_tag_name'] = df_questions['questions_tag_name'].str.split(',').apply(set).str.join(',')\n",
        "\n",
        "\n",
        "# fill nan with 'No Tag' if any \n",
        "prof_copy['professional_all_tags'] = prof_copy['professional_all_tags'].fillna('No Tag')\n",
        "# replace \"\" with \"No Tag\", because previously we replace nan with \"\"\n",
        "prof_copy['professional_all_tags'] = prof_copy['professional_all_tags'].replace('', 'No Tag')\n",
        "prof_copy['professionals_location'] = prof_copy['professionals_location'].fillna('No Location')\n",
        "prof_copy['professionals_industry'] = prof_copy['professionals_industry'].fillna('No Industry')\n",
        "\n",
        "# remove duplicates tags from each professionals \n",
        "prof_copy['professional_all_tags'] = prof_copy['professional_all_tags'].str.split(',').apply(set).str.join(',')\n",
        "\n",
        "\n",
        "\n",
        "# remove some null values from df_merge\n",
        "original['num_ans_per_ques']  = original['num_ans_per_ques'].fillna(0)\n",
        "original['num_tags_professional'] = original['num_tags_professional'].fillna(0)\n",
        "original['num_tags_question'] = original['num_tags_question'].fillna(0)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fshzZ2xPvhkZ"
      },
      "source": [
        "# **Building model in LightFM**\n",
        "In this steps, we are going to build our lighFM model using lightFM python library. Firstly, we have to create lightFM Dataset for our model. LightFM Datset class makes it really easy for us for creating interection matrix, weights and user/item features.\n",
        "\n",
        "interection matrix: It is a matrix that contains user/ item interections or professional/quesiton intereactions.\n",
        "weights: weight of interection matrix. Less weight means less importance to that interection matrix.\n",
        "user/item features: user/item features supplied as like this (user_id, ['feature_1', 'feature_2', 'feature_3'])\n",
        "If you want to how lightfm python library's dataset class works and how to use it, please go to this link Building LightFM Datasets.\n",
        "\n",
        "Then, after that we will be start building our LightFM model using LightFM class. LightFM class makes it really easy for making lightFM model. After that we will train our model by our data.\n",
        "\n",
        "Creating features list for Dataset class: LightFM library has a Dataset class that makes it really easy for building necessary information for model. But we have feed set of all professionals/questions unique ids and all questions and professional features list. This will create internel mapping for lightFM to use."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0L07iQTo5MH"
      },
      "source": [
        "**Creating features list for Dataset class:** \n",
        "LightFM library has a Dataset class that makes it really easy for building necessary information for model. But we have feed set of all professionals/questions unique ids and all questions and professional features list. This will create internel mapping for lightFM to use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnclqm3AuLI_",
        "outputId": "7acf4256-8445-46b8-87bc-b27b133221d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# generating features list for mapping \n",
        "question_feature_list = generate_feature_list(\n",
        "    df_questions,\n",
        "    ['questions_tag_name'])\n",
        "\n",
        "question_feature_list.head()\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    professor\n",
              "1      college\n",
              "2      lecture\n",
              "3         army\n",
              "4     military\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prqE5n0luLGg"
      },
      "source": [
        "# df_questions.head()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEV_-5F8uLDc",
        "outputId": "3346a70e-0e4f-4768-8538-7f0c0a271eec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "professional_feature_list = generate_feature_list(\n",
        "    prof_copy,\n",
        "    ['professional_all_tags'])\n",
        "\n",
        "professional_feature_list.head()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        resume\n",
              "1    consulting\n",
              "2        No Tag\n",
              "3          hire\n",
              "4        doctor\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKy-NnxiweVt",
        "outputId": "aa7670f9-8a36-4676-b56d-d179e55a6ade",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "prof_copy.head()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>professionals_id</th>\n",
              "      <th>professionals_location</th>\n",
              "      <th>professionals_industry</th>\n",
              "      <th>professionals_headline</th>\n",
              "      <th>professionals_date_joined</th>\n",
              "      <th>professionals_id_num</th>\n",
              "      <th>tag_users_user_id</th>\n",
              "      <th>professionals_tag_name</th>\n",
              "      <th>questions_tag_name</th>\n",
              "      <th>professional_all_tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9ced4ce7519049c0944147afb75a8ce3</td>\n",
              "      <td>No Location</td>\n",
              "      <td>No Industry</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2011-10-05 20:35:19+00:00</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>resume,consulting</td>\n",
              "      <td>resume,consulting</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>f718dcf6d2ec4cb0a52a9db59d7f9e67</td>\n",
              "      <td>No Location</td>\n",
              "      <td>No Industry</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2011-10-05 20:49:21+00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>No Tag</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0c673e046d824ec0ad0ebe012a0673e4</td>\n",
              "      <td>New York, New York</td>\n",
              "      <td>No Industry</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2011-10-18 17:31:26+00:00</td>\n",
              "      <td>2</td>\n",
              "      <td>0c673e046d824ec0ad0ebe012a0673e4</td>\n",
              "      <td>consulting,consulting,consulting,consulting,co...</td>\n",
              "      <td>hire,doctor,justice,detective,consulting,mecha...</td>\n",
              "      <td>hire,doctor,justice,detective,consulting,mecha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>977428d851b24183b223be0eb8619a8c</td>\n",
              "      <td>Boston, Massachusetts</td>\n",
              "      <td>No Industry</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2011-11-09 20:39:29+00:00</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>justice,detective,forensic,neurosurgeon,math,c...</td>\n",
              "      <td>justice,detective,forensic,neurosurgeon,math,c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>e2d57e5041a44f489288397c9904c2b2</td>\n",
              "      <td>No Location</td>\n",
              "      <td>No Industry</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2011-12-10 22:14:44+00:00</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>No Tag</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   professionals_id  ...                              professional_all_tags\n",
              "0  9ced4ce7519049c0944147afb75a8ce3  ...                                  resume,consulting\n",
              "1  f718dcf6d2ec4cb0a52a9db59d7f9e67  ...                                             No Tag\n",
              "2  0c673e046d824ec0ad0ebe012a0673e4  ...  hire,doctor,justice,detective,consulting,mecha...\n",
              "3  977428d851b24183b223be0eb8619a8c  ...  justice,detective,forensic,neurosurgeon,math,c...\n",
              "4  e2d57e5041a44f489288397c9904c2b2  ...                                             No Tag\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzHC3pNIuLAk"
      },
      "source": [
        "# # calculate our weight value "
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FG3ydZ-uK-E"
      },
      "source": [
        "# calculate our weight value \n",
        "original['total_weights'] = 1 / (\n",
        "    original['num_ans_per_ques'])\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOQJeXNQuKz2"
      },
      "source": [
        "# creating features for feeding into lightfm \n",
        "df_questions['question_features'] = create_features(\n",
        "    df_questions, ['questions_tag_name'], \n",
        "    'questions_id_num')\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxGLLX4PLmTd",
        "outputId": "f66d4b3e-15bd-412b-9648-9c935bbc1ad1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "source": [
        "df_questions.head()\n",
        "# question_features ka mtlb hai k user ki id or usky tags\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>questions_id</th>\n",
              "      <th>questions_author_id</th>\n",
              "      <th>questions_date_added</th>\n",
              "      <th>questions_title</th>\n",
              "      <th>questions_body</th>\n",
              "      <th>questions_id_num</th>\n",
              "      <th>tag_questions_question_id</th>\n",
              "      <th>questions_tag_name</th>\n",
              "      <th>id</th>\n",
              "      <th>score</th>\n",
              "      <th>students_id</th>\n",
              "      <th>students_location</th>\n",
              "      <th>students_date_joined</th>\n",
              "      <th>students_id_num</th>\n",
              "      <th>question_features</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>332a511f1569444485cf7a7a556a5e54</td>\n",
              "      <td>8f6f374ffd834d258ab69d376dd998f5</td>\n",
              "      <td>2016-04-26 11:14:26+00:00</td>\n",
              "      <td>Teacher   career   question</td>\n",
              "      <td>What  is  a  maths  teacher?   what  is  a  ma...</td>\n",
              "      <td>0</td>\n",
              "      <td>332a511f1569444485cf7a7a556a5e54</td>\n",
              "      <td>professor,college,lecture</td>\n",
              "      <td>332a511f1569444485cf7a7a556a5e54</td>\n",
              "      <td>1</td>\n",
              "      <td>8f6f374ffd834d258ab69d376dd998f5</td>\n",
              "      <td>Coimbatore, Tamil Nadu, India</td>\n",
              "      <td>2016-04-22 10:07:32+00:00</td>\n",
              "      <td>6890.0</td>\n",
              "      <td>(0, [professor, college, lecture])</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>eb80205482e4424cad8f16bc25aa2d9c</td>\n",
              "      <td>acccbda28edd4362ab03fb8b6fd2d67b</td>\n",
              "      <td>2016-05-20 16:48:25+00:00</td>\n",
              "      <td>I want to become an army officer. What can I d...</td>\n",
              "      <td>I am Priyanka from Bangalore . Now am in 10th ...</td>\n",
              "      <td>1</td>\n",
              "      <td>eb80205482e4424cad8f16bc25aa2d9c</td>\n",
              "      <td>army,military</td>\n",
              "      <td>eb80205482e4424cad8f16bc25aa2d9c</td>\n",
              "      <td>5</td>\n",
              "      <td>acccbda28edd4362ab03fb8b6fd2d67b</td>\n",
              "      <td>Providence, Rhode Island</td>\n",
              "      <td>2016-05-20 16:29:08+00:00</td>\n",
              "      <td>10189.0</td>\n",
              "      <td>(1, [army, military])</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4ec31632938a40b98909416bdd0decff</td>\n",
              "      <td>f2c179a563024ccc927399ce529094b5</td>\n",
              "      <td>2017-02-08 19:13:38+00:00</td>\n",
              "      <td>Will going abroad for your first job increase ...</td>\n",
              "      <td>I'm planning on going abroad for my first job....</td>\n",
              "      <td>2</td>\n",
              "      <td>4ec31632938a40b98909416bdd0decff</td>\n",
              "      <td>overseas,working-abroad</td>\n",
              "      <td>4ec31632938a40b98909416bdd0decff</td>\n",
              "      <td>2</td>\n",
              "      <td>f2c179a563024ccc927399ce529094b5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2017-02-07 15:51:57+00:00</td>\n",
              "      <td>18023.0</td>\n",
              "      <td>(2, [overseas, working-abroad])</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2f6a9a99d9b24e5baa50d40d0ba50a75</td>\n",
              "      <td>2c30ffba444e40eabb4583b55233a5a4</td>\n",
              "      <td>2017-09-01 14:05:32+00:00</td>\n",
              "      <td>To become a specialist in business  management...</td>\n",
              "      <td>i hear business management is a hard way to ge...</td>\n",
              "      <td>3</td>\n",
              "      <td>2f6a9a99d9b24e5baa50d40d0ba50a75</td>\n",
              "      <td>business,networking</td>\n",
              "      <td>2f6a9a99d9b24e5baa50d40d0ba50a75</td>\n",
              "      <td>2</td>\n",
              "      <td>2c30ffba444e40eabb4583b55233a5a4</td>\n",
              "      <td>North Lauderdale, Florida</td>\n",
              "      <td>2017-09-01 14:02:02+00:00</td>\n",
              "      <td>20803.0</td>\n",
              "      <td>(3, [business, networking])</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5af8880460c141dbb02971a1a8369529</td>\n",
              "      <td>aa9eb1a2ab184ebbb00dc01ab663428a</td>\n",
              "      <td>2017-09-01 02:36:54+00:00</td>\n",
              "      <td>Are there any scholarships out there for stude...</td>\n",
              "      <td>I'm trying to find scholarships for first year...</td>\n",
              "      <td>4</td>\n",
              "      <td>5af8880460c141dbb02971a1a8369529</td>\n",
              "      <td>scholarships,firstgeneration,highschoolsenior,...</td>\n",
              "      <td>5af8880460c141dbb02971a1a8369529</td>\n",
              "      <td>2</td>\n",
              "      <td>aa9eb1a2ab184ebbb00dc01ab663428a</td>\n",
              "      <td>Tunnel Hill, Georgia</td>\n",
              "      <td>2017-09-01 02:29:06+00:00</td>\n",
              "      <td>20505.0</td>\n",
              "      <td>(4, [scholarships, firstgeneration, highschool...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       questions_id  ...                                  question_features\n",
              "0  332a511f1569444485cf7a7a556a5e54  ...                 (0, [professor, college, lecture])\n",
              "1  eb80205482e4424cad8f16bc25aa2d9c  ...                              (1, [army, military])\n",
              "2  4ec31632938a40b98909416bdd0decff  ...                    (2, [overseas, working-abroad])\n",
              "3  2f6a9a99d9b24e5baa50d40d0ba50a75  ...                        (3, [business, networking])\n",
              "4  5af8880460c141dbb02971a1a8369529  ...  (4, [scholarships, firstgeneration, highschool...\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u20c76d7LmQY"
      },
      "source": [
        "prof_copy['professional_features'] = create_features(\n",
        "    prof_copy,\n",
        "    ['professional_all_tags'],\n",
        "    'professionals_id_num')\n",
        "\n",
        "# yha par bhi same oper vala kaam ho rha hai, so no need to show the output again. \n",
        "# professional_features ka mtlb hai k professional ki id or usky tags\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVF3FqOTZ4e_",
        "outputId": "ca2d8f5b-7e68-45ca-8f4c-8af7ada6d980",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "prof_copy.head()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>professionals_id</th>\n",
              "      <th>professionals_location</th>\n",
              "      <th>professionals_industry</th>\n",
              "      <th>professionals_headline</th>\n",
              "      <th>professionals_date_joined</th>\n",
              "      <th>professionals_id_num</th>\n",
              "      <th>tag_users_user_id</th>\n",
              "      <th>professionals_tag_name</th>\n",
              "      <th>questions_tag_name</th>\n",
              "      <th>professional_all_tags</th>\n",
              "      <th>professional_features</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9ced4ce7519049c0944147afb75a8ce3</td>\n",
              "      <td>No Location</td>\n",
              "      <td>No Industry</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2011-10-05 20:35:19+00:00</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>resume,consulting</td>\n",
              "      <td>resume,consulting</td>\n",
              "      <td>(0, [resume, consulting])</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>f718dcf6d2ec4cb0a52a9db59d7f9e67</td>\n",
              "      <td>No Location</td>\n",
              "      <td>No Industry</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2011-10-05 20:49:21+00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>No Tag</td>\n",
              "      <td>(1, [No Tag])</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0c673e046d824ec0ad0ebe012a0673e4</td>\n",
              "      <td>New York, New York</td>\n",
              "      <td>No Industry</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2011-10-18 17:31:26+00:00</td>\n",
              "      <td>2</td>\n",
              "      <td>0c673e046d824ec0ad0ebe012a0673e4</td>\n",
              "      <td>consulting,consulting,consulting,consulting,co...</td>\n",
              "      <td>hire,doctor,justice,detective,consulting,mecha...</td>\n",
              "      <td>hire,doctor,justice,detective,consulting,mecha...</td>\n",
              "      <td>(2, [hire, doctor, justice, detective, consult...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>977428d851b24183b223be0eb8619a8c</td>\n",
              "      <td>Boston, Massachusetts</td>\n",
              "      <td>No Industry</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2011-11-09 20:39:29+00:00</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>justice,detective,forensic,neurosurgeon,math,c...</td>\n",
              "      <td>justice,detective,forensic,neurosurgeon,math,c...</td>\n",
              "      <td>(3, [justice, detective, forensic, neurosurgeo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>e2d57e5041a44f489288397c9904c2b2</td>\n",
              "      <td>No Location</td>\n",
              "      <td>No Industry</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2011-12-10 22:14:44+00:00</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>No Tag</td>\n",
              "      <td>(4, [No Tag])</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   professionals_id  ...                              professional_features\n",
              "0  9ced4ce7519049c0944147afb75a8ce3  ...                          (0, [resume, consulting])\n",
              "1  f718dcf6d2ec4cb0a52a9db59d7f9e67  ...                                      (1, [No Tag])\n",
              "2  0c673e046d824ec0ad0ebe012a0673e4  ...  (2, [hire, doctor, justice, detective, consult...\n",
              "3  977428d851b24183b223be0eb8619a8c  ...  (3, [justice, detective, forensic, neurosurgeo...\n",
              "4  e2d57e5041a44f489288397c9904c2b2  ...                                      (4, [No Tag])\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_iOT3Kz3MfEZ"
      },
      "source": [
        "**LightFM Dataset**: In this steps we are going to build lightfm datasets. And then we will be building our interactions matrix, weights and professional/question features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pdKsk-3PIvd"
      },
      "source": [
        "**To do this, we create a dataset and call its fit method. The first argument is an iterable of all user ids in our data, and the second is an iterable of all item ids. In this case, we use generator expressions to lazily iterate over our data and yield user and item ids:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdwAtW3BLmJy"
      },
      "source": [
        "from lightfm.data import Dataset\n",
        "\n",
        "dataset = Dataset()\n",
        "dataset.fit(\n",
        "    set(df_professionals['professionals_id_num']), \n",
        "    set(df_questions['questions_id_num']),\n",
        "    item_features=question_feature_list, \n",
        "    user_features=professional_feature_list)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmhw_0wzMvKc",
        "outputId": "67286c3c-a04c-486e-b732-dd44b8a380f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "source": [
        "# now we are building interactions matrix between professionals and questions\n",
        "# we are passing professional and questions id as a tuple\n",
        "# e.g -> pd.Series((pro_id, question_id), (pro_id, questin_id))\n",
        "# then we use lightfm build in method for building interactions matrix\n",
        "original['author_question_id_tuple'] = list(zip(\n",
        "    original['professionals_id_num'], original.questions_id_num, original.total_weights))\n",
        "\n",
        "original.head()\n",
        "# ak hi author ny multiple swaalo k jawab dye hue hain (author, question_id, weitage)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>answers_id</th>\n",
              "      <th>answers_author_id</th>\n",
              "      <th>answers_question_id</th>\n",
              "      <th>answers_date_added</th>\n",
              "      <th>answers_body</th>\n",
              "      <th>answers_id_num</th>\n",
              "      <th>questions_id</th>\n",
              "      <th>questions_author_id</th>\n",
              "      <th>questions_date_added</th>\n",
              "      <th>questions_title</th>\n",
              "      <th>questions_body</th>\n",
              "      <th>questions_id_num</th>\n",
              "      <th>tag_questions_question_id</th>\n",
              "      <th>questions_tag_name</th>\n",
              "      <th>id_x</th>\n",
              "      <th>score_x</th>\n",
              "      <th>students_id</th>\n",
              "      <th>students_location</th>\n",
              "      <th>students_date_joined</th>\n",
              "      <th>students_id_num</th>\n",
              "      <th>professionals_id</th>\n",
              "      <th>professionals_location</th>\n",
              "      <th>professionals_industry</th>\n",
              "      <th>professionals_headline</th>\n",
              "      <th>professionals_date_joined</th>\n",
              "      <th>professionals_id_num</th>\n",
              "      <th>tag_users_user_id</th>\n",
              "      <th>professionals_tag_name</th>\n",
              "      <th>id_y</th>\n",
              "      <th>score_y</th>\n",
              "      <th>num_of_ans_by_professional</th>\n",
              "      <th>num_ans_per_ques</th>\n",
              "      <th>num_tags_professional</th>\n",
              "      <th>num_tags_question</th>\n",
              "      <th>total_weights</th>\n",
              "      <th>author_question_id_tuple</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4e5f01128cae4f6d8fd697cec5dca60c</td>\n",
              "      <td>36ff3b3666df400f956f8335cf53e09e</td>\n",
              "      <td>332a511f1569444485cf7a7a556a5e54</td>\n",
              "      <td>2016-04-29 19:40:14+00:00</td>\n",
              "      <td>&lt;p&gt;Hi!&lt;/p&gt;\\n&lt;p&gt;You are asking a very interesti...</td>\n",
              "      <td>0</td>\n",
              "      <td>332a511f1569444485cf7a7a556a5e54</td>\n",
              "      <td>8f6f374ffd834d258ab69d376dd998f5</td>\n",
              "      <td>2016-04-26 11:14:26+00:00</td>\n",
              "      <td>Teacher   career   question</td>\n",
              "      <td>What  is  a  maths  teacher?   what  is  a  ma...</td>\n",
              "      <td>0</td>\n",
              "      <td>332a511f1569444485cf7a7a556a5e54</td>\n",
              "      <td>lecture,college,professor</td>\n",
              "      <td>332a511f1569444485cf7a7a556a5e54</td>\n",
              "      <td>1.0</td>\n",
              "      <td>8f6f374ffd834d258ab69d376dd998f5</td>\n",
              "      <td>Coimbatore, Tamil Nadu, India</td>\n",
              "      <td>2016-04-22 10:07:32+00:00</td>\n",
              "      <td>6890.0</td>\n",
              "      <td>36ff3b3666df400f956f8335cf53e09e</td>\n",
              "      <td>Cleveland, Ohio</td>\n",
              "      <td>Mental Health Care</td>\n",
              "      <td>Assist with Recognizing and Developing Potential</td>\n",
              "      <td>2015-10-19 20:56:49+00:00</td>\n",
              "      <td>2410</td>\n",
              "      <td>36ff3b3666df400f956f8335cf53e09e</td>\n",
              "      <td>engineering,computer-science,science,college,e...</td>\n",
              "      <td>332a511f1569444485cf7a7a556a5e54</td>\n",
              "      <td>1</td>\n",
              "      <td>1710</td>\n",
              "      <td>1</td>\n",
              "      <td>12.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>(2410, 0, 1.0)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>f3519ab99a1a4a13a8a9ecb814287d2a</td>\n",
              "      <td>36ff3b3666df400f956f8335cf53e09e</td>\n",
              "      <td>0f1d6a4f276c4a05878dd48e03e52289</td>\n",
              "      <td>2016-07-31 15:35:54+00:00</td>\n",
              "      <td>&lt;p&gt;Hi Rodrigo!&lt;/p&gt;\\n&lt;p&gt;The important thing to ...</td>\n",
              "      <td>11</td>\n",
              "      <td>0f1d6a4f276c4a05878dd48e03e52289</td>\n",
              "      <td>585ac233015447cc9e9a217044e515e1</td>\n",
              "      <td>2016-05-19 22:16:25+00:00</td>\n",
              "      <td>what kind of  college could i go  to for a soc...</td>\n",
              "      <td>I like soccer because i been playing sense i w...</td>\n",
              "      <td>7</td>\n",
              "      <td>0f1d6a4f276c4a05878dd48e03e52289</td>\n",
              "      <td>college,building,soccer</td>\n",
              "      <td>0f1d6a4f276c4a05878dd48e03e52289</td>\n",
              "      <td>1.0</td>\n",
              "      <td>585ac233015447cc9e9a217044e515e1</td>\n",
              "      <td>Morgan Hill, California</td>\n",
              "      <td>2016-05-19 22:08:48+00:00</td>\n",
              "      <td>10014.0</td>\n",
              "      <td>36ff3b3666df400f956f8335cf53e09e</td>\n",
              "      <td>Cleveland, Ohio</td>\n",
              "      <td>Mental Health Care</td>\n",
              "      <td>Assist with Recognizing and Developing Potential</td>\n",
              "      <td>2015-10-19 20:56:49+00:00</td>\n",
              "      <td>2410</td>\n",
              "      <td>36ff3b3666df400f956f8335cf53e09e</td>\n",
              "      <td>engineering,computer-science,science,college,e...</td>\n",
              "      <td>0f1d6a4f276c4a05878dd48e03e52289</td>\n",
              "      <td>1</td>\n",
              "      <td>1710</td>\n",
              "      <td>1</td>\n",
              "      <td>12.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>(2410, 7, 1.0)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>825f6e316a5f48328d6f8af831df9940</td>\n",
              "      <td>36ff3b3666df400f956f8335cf53e09e</td>\n",
              "      <td>0149c6d63e214040b44d4a3789bb00ba</td>\n",
              "      <td>2018-04-15 23:08:46+00:00</td>\n",
              "      <td>&lt;p&gt;Congratulations on being interested in find...</td>\n",
              "      <td>71</td>\n",
              "      <td>0149c6d63e214040b44d4a3789bb00ba</td>\n",
              "      <td>34217a1861d640a58c85e033414cf9cb</td>\n",
              "      <td>2018-04-12 17:13:45+00:00</td>\n",
              "      <td>What is the best way to prepare for studying e...</td>\n",
              "      <td>I am interested in Computational Neuroscience,...</td>\n",
              "      <td>33</td>\n",
              "      <td>0149c6d63e214040b44d4a3789bb00ba</td>\n",
              "      <td>engineering,neuroscience,gradschool</td>\n",
              "      <td>0149c6d63e214040b44d4a3789bb00ba</td>\n",
              "      <td>2.0</td>\n",
              "      <td>34217a1861d640a58c85e033414cf9cb</td>\n",
              "      <td>Austin, Texas</td>\n",
              "      <td>2018-04-12 17:09:31+00:00</td>\n",
              "      <td>26796.0</td>\n",
              "      <td>36ff3b3666df400f956f8335cf53e09e</td>\n",
              "      <td>Cleveland, Ohio</td>\n",
              "      <td>Mental Health Care</td>\n",
              "      <td>Assist with Recognizing and Developing Potential</td>\n",
              "      <td>2015-10-19 20:56:49+00:00</td>\n",
              "      <td>2410</td>\n",
              "      <td>36ff3b3666df400f956f8335cf53e09e</td>\n",
              "      <td>engineering,computer-science,science,college,e...</td>\n",
              "      <td>0149c6d63e214040b44d4a3789bb00ba</td>\n",
              "      <td>2</td>\n",
              "      <td>1710</td>\n",
              "      <td>2</td>\n",
              "      <td>12.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>(2410, 33, 0.5)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>fb2c794175304c4caeb55e654270421f</td>\n",
              "      <td>a32736b04c27437da3078374d47af1b1</td>\n",
              "      <td>0149c6d63e214040b44d4a3789bb00ba</td>\n",
              "      <td>2018-04-13 18:18:05+00:00</td>\n",
              "      <td>&lt;p&gt;Hi Elisabeth! &lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;If you are ...</td>\n",
              "      <td>72</td>\n",
              "      <td>0149c6d63e214040b44d4a3789bb00ba</td>\n",
              "      <td>34217a1861d640a58c85e033414cf9cb</td>\n",
              "      <td>2018-04-12 17:13:45+00:00</td>\n",
              "      <td>What is the best way to prepare for studying e...</td>\n",
              "      <td>I am interested in Computational Neuroscience,...</td>\n",
              "      <td>33</td>\n",
              "      <td>0149c6d63e214040b44d4a3789bb00ba</td>\n",
              "      <td>engineering,neuroscience,gradschool</td>\n",
              "      <td>0149c6d63e214040b44d4a3789bb00ba</td>\n",
              "      <td>2.0</td>\n",
              "      <td>34217a1861d640a58c85e033414cf9cb</td>\n",
              "      <td>Austin, Texas</td>\n",
              "      <td>2018-04-12 17:09:31+00:00</td>\n",
              "      <td>26796.0</td>\n",
              "      <td>a32736b04c27437da3078374d47af1b1</td>\n",
              "      <td>San Francisco, California</td>\n",
              "      <td>Computer Software</td>\n",
              "      <td>Product Management @ Okta</td>\n",
              "      <td>2018-04-13 17:48:09+00:00</td>\n",
              "      <td>18373</td>\n",
              "      <td>a32736b04c27437da3078374d47af1b1</td>\n",
              "      <td>computer-software</td>\n",
              "      <td>0149c6d63e214040b44d4a3789bb00ba</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>(18373, 33, 0.5)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>f3fc23809cda472780fc565334f35000</td>\n",
              "      <td>36ff3b3666df400f956f8335cf53e09e</td>\n",
              "      <td>acc611cfb5c44daa8a3d7d65dfffa5ff</td>\n",
              "      <td>2018-08-14 10:37:01+00:00</td>\n",
              "      <td>&lt;p&gt;The most important thing that you can do is...</td>\n",
              "      <td>102</td>\n",
              "      <td>acc611cfb5c44daa8a3d7d65dfffa5ff</td>\n",
              "      <td>5b751a8ee4a047f7a08ce9eb5e43e5a2</td>\n",
              "      <td>2018-08-14 04:49:33+00:00</td>\n",
              "      <td>How should I prepare myself for my job search ...</td>\n",
              "      <td>I am a Sociology, Political Science, and Inter...</td>\n",
              "      <td>47</td>\n",
              "      <td>acc611cfb5c44daa8a3d7d65dfffa5ff</td>\n",
              "      <td>job-search,career-choice,job,college-jobs</td>\n",
              "      <td>acc611cfb5c44daa8a3d7d65dfffa5ff</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5b751a8ee4a047f7a08ce9eb5e43e5a2</td>\n",
              "      <td>Kingston, Pennsylvania</td>\n",
              "      <td>2018-08-14 04:47:13+00:00</td>\n",
              "      <td>28533.0</td>\n",
              "      <td>36ff3b3666df400f956f8335cf53e09e</td>\n",
              "      <td>Cleveland, Ohio</td>\n",
              "      <td>Mental Health Care</td>\n",
              "      <td>Assist with Recognizing and Developing Potential</td>\n",
              "      <td>2015-10-19 20:56:49+00:00</td>\n",
              "      <td>2410</td>\n",
              "      <td>36ff3b3666df400f956f8335cf53e09e</td>\n",
              "      <td>engineering,computer-science,science,college,e...</td>\n",
              "      <td>acc611cfb5c44daa8a3d7d65dfffa5ff</td>\n",
              "      <td>1</td>\n",
              "      <td>1710</td>\n",
              "      <td>1</td>\n",
              "      <td>12.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>(2410, 47, 1.0)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         answers_id  ... author_question_id_tuple\n",
              "0  4e5f01128cae4f6d8fd697cec5dca60c  ...           (2410, 0, 1.0)\n",
              "1  f3519ab99a1a4a13a8a9ecb814287d2a  ...           (2410, 7, 1.0)\n",
              "2  825f6e316a5f48328d6f8af831df9940  ...          (2410, 33, 0.5)\n",
              "3  fb2c794175304c4caeb55e654270421f  ...         (18373, 33, 0.5)\n",
              "4  f3fc23809cda472780fc565334f35000  ...          (2410, 47, 1.0)\n",
              "\n",
              "[5 rows x 36 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0AIFgVLMvG4"
      },
      "source": [
        "interactions, weights = dataset.build_interactions(\n",
        "    original['author_question_id_tuple'])"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEiElsyQMvDd"
      },
      "source": [
        "# now we are building our questions and professionals features\n",
        "# in a way that lightfm understand.\n",
        "# we are using lightfm build in method for building\n",
        "# questions and professionals features \n",
        "questions_features = dataset.build_item_features(\n",
        "    df_questions['question_features'])\n",
        "\n",
        "professional_features = dataset.build_user_features(\n",
        "    prof_copy['professional_features'])\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qdk-0s3-Z_9J"
      },
      "source": [
        "**Model building and training:** \n",
        "In ths steps, I am going to build lightfm model and then train the model. If you want to learn how to create lightfm model using this library please read this post recommender for the Movielens dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcRRPknPMu_W",
        "outputId": "cca8da6c-901c-438c-c35b-e2a20e5b3ef0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "################################\n",
        "# Model building part\n",
        "################################\n",
        "\n",
        "# define lightfm model by specifying hyper-parametre\n",
        "# then fit the model with ineteractions matrix, item and user features \n",
        "\n",
        "from lightfm import LightFM\n",
        "from lightfm.data import Dataset\n",
        "\n",
        "model = LightFM(\n",
        "    no_components=150,\n",
        "    learning_rate=0.05,\n",
        "    loss='warp',\n",
        "    random_state=2019)\n",
        "\n",
        "model.fit(\n",
        "    interactions,\n",
        "    item_features=questions_features,\n",
        "    user_features=professional_features, sample_weight=weights,\n",
        "    epochs=10, num_threads=4, verbose=True)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0\n",
            "Epoch 1\n",
            "Epoch 2\n",
            "Epoch 3\n",
            "Epoch 4\n",
            "Epoch 5\n",
            "Epoch 6\n",
            "Epoch 7\n",
            "Epoch 8\n",
            "Epoch 9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<lightfm.lightfm.LightFM at 0x7fa2d5fc27b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uL8NO1auoatP"
      },
      "source": [
        "**Evaluating the performance of the model**\n",
        "Now we have to evaluate our model to see it's performance. No matter how good your model is, if you can't evaluate your model correctly you can't improve and trust your model. For recommendation problem, there is not very good matrics for evaluating. But luckily lightfm provides us a very rich set of evaluating matrics. In this steps, we will be calculating AUC scores for our model.\n",
        "\n",
        "What is AUC score in lightfm library?: It measure the ROC AUC metric for a model: the probability that a randomly chosen positive example has a higher score than a randomly chosen negative example. A perfect score is 1.0.\n",
        "\n",
        "Let's see what is our model score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaSTMGgkMu73",
        "outputId": "6fe90bc5-3f07-4a61-8e9e-8c17e94f6f98",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "calculate_auc_score(model, interactions, questions_features, professional_features)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.95613337"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMz7EGZ9qx-P"
      },
      "source": [
        "**Make real recommendations:**\n",
        "\n",
        "Now we already see how our model is by looking at AUC score. But now let's see some real example of recommendation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgvpTTbbMu4M"
      },
      "source": [
        "from IPython.display import display_html\n",
        "def display_side_by_side(*args):\n",
        "    html_str=''\n",
        "    for df in args:\n",
        "        html_str+=df.to_html()\n",
        "    display_html(html_str.replace('table','table style=\"display:inline\"'),raw=True)\n",
        "\n",
        "def recommend_questions(professional_ids):\n",
        "     \n",
        "    for professional in professional_ids:\n",
        "        # print their previous answered question title\n",
        "        previous_q_id_num = original.loc[original['professionals_id_num'] == professional][:3]['questions_id_num']\n",
        "        df_previous_questions = df_questions.loc[df_questions['questions_id_num'].isin(previous_q_id_num)]\n",
        "        print('Professional Id (' + str(professional) + \"): Previous Answered Questions\")\n",
        "        display_side_by_side(\n",
        "            df_previous_questions[['questions_title', 'question_features']],\n",
        "            df_professionals.loc[df_professionals.professionals_id_num == professional][['professionals_id_num','professionals_tag_name']])\n",
        "        \n",
        "        # predict\n",
        "        discard_qu_id = df_previous_questions['questions_id_num'].values.tolist()\n",
        "        df_use_for_prediction = df_questions.loc[~df_questions['questions_id_num'].isin(discard_qu_id)]\n",
        "        questions_id_for_predict = df_use_for_prediction['questions_id_num'].values.tolist()\n",
        "        \n",
        "        scores = model.predict(\n",
        "            professional,\n",
        "            questions_id_for_predict,\n",
        "            item_features=questions_features,\n",
        "            user_features=professional_features)\n",
        "        \n",
        "        df_use_for_prediction['scores'] = scores\n",
        "        df_use_for_prediction = df_use_for_prediction.sort_values(by='scores', ascending=False)[:8]\n",
        "        print('Professional Id (' + str(professional) + \"): Recommended Questions: \")\n",
        "        display(df_use_for_prediction[['questions_title', 'question_features']])"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GT3jMSznMu0h",
        "outputId": "59060f1c-cca6-4253-9dbb-3684cb3c6cae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "recommend_questions([1200 ,19897, 3])"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Professional Id (1200): Previous Answered Questions\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>questions_title</th>\n",
              "      <th>question_features</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table style=\"display:inline\"><table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>professionals_id_num</th>\n",
              "      <th>professionals_tag_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1200</th>\n",
              "      <td>1200</td>\n",
              "      <td>marketing,strategy,entrepreneurship,management,java,advertising,python,data-analysis,online-advertising,real-estate,team-leadership,dj,analytics,display-advertising,football,blackjack,hip-hop,billiards,break</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table style=\"display:inline\">"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Professional Id (1200): Recommended Questions: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>questions_title</th>\n",
              "      <th>question_features</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>19011</th>\n",
              "      <td>How do you get started in starting your own bu...</td>\n",
              "      <td>(19011, [marketing, management, business])</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14451</th>\n",
              "      <td>What is the best way to find a good internship...</td>\n",
              "      <td>(14451, [marketing, business])</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22676</th>\n",
              "      <td>What are some specific daily responsibilities ...</td>\n",
              "      <td>(22676, [marketing, business, marketing-and-ad...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23680</th>\n",
              "      <td>what makes markerting so important in business?</td>\n",
              "      <td>(23680, [marketing, business])</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12133</th>\n",
              "      <td>What qualities and skills do startups look for...</td>\n",
              "      <td>(12133, [business, startups, entrepreneurship])</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>829</th>\n",
              "      <td>Is advertising a good major?</td>\n",
              "      <td>(829, [design, communications, marketing, busi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9330</th>\n",
              "      <td>how can i get my business heard of ?</td>\n",
              "      <td>(9330, [marketing, advertising, entrepreneursh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20821</th>\n",
              "      <td>What are the main challenges an entrepreneur f...</td>\n",
              "      <td>(20821, [business, startups, entrepreneurship])</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         questions_title                                  question_features\n",
              "19011  How do you get started in starting your own bu...         (19011, [marketing, management, business])\n",
              "14451  What is the best way to find a good internship...                     (14451, [marketing, business])\n",
              "22676  What are some specific daily responsibilities ...  (22676, [marketing, business, marketing-and-ad...\n",
              "23680    what makes markerting so important in business?                     (23680, [marketing, business])\n",
              "12133  What qualities and skills do startups look for...    (12133, [business, startups, entrepreneurship])\n",
              "829                         Is advertising a good major?  (829, [design, communications, marketing, busi...\n",
              "9330                how can i get my business heard of ?  (9330, [marketing, advertising, entrepreneursh...\n",
              "20821  What are the main challenges an entrepreneur f...    (20821, [business, startups, entrepreneurship])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Professional Id (19897): Previous Answered Questions\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>questions_title</th>\n",
              "      <th>question_features</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>22784</th>\n",
              "      <td>Do companies truly focus on your college major when applying for jobs?</td>\n",
              "      <td>(22784, [major])</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table style=\"display:inline\"><table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>professionals_id_num</th>\n",
              "      <th>professionals_tag_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>19897</th>\n",
              "      <td>19897</td>\n",
              "      <td>illustration,graphic-design,adobe-creative-suite,comic-books</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table style=\"display:inline\">"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Professional Id (19897): Recommended Questions: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>questions_title</th>\n",
              "      <th>question_features</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>19407</th>\n",
              "      <td>How can you be a successful photographer? What...</td>\n",
              "      <td>(19407, [graphic-design, photography, art])</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2310</th>\n",
              "      <td>what is one of best things about being an anim...</td>\n",
              "      <td>(2310, [design, animation, art, artist])</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9682</th>\n",
              "      <td>How to get started in animation?</td>\n",
              "      <td>(9682, [animation, art, artist])</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11231</th>\n",
              "      <td>Do I have to live in a big city to do well in ...</td>\n",
              "      <td>(11231, [design, art, artist, graphic-design, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13484</th>\n",
              "      <td>Would a Graphic Design degree be a feesible op...</td>\n",
              "      <td>(13484, [graphic-design, art])</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6058</th>\n",
              "      <td>How should you start in the Graphic Design ind...</td>\n",
              "      <td>(6058, [graphic-design, design, art])</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16967</th>\n",
              "      <td>How do you get a job in a competitive work field?</td>\n",
              "      <td>(16967, [photography, art])</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19275</th>\n",
              "      <td>how do i get my content (animations) out in th...</td>\n",
              "      <td>(19275, [animation, art])</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         questions_title                                  question_features\n",
              "19407  How can you be a successful photographer? What...        (19407, [graphic-design, photography, art])\n",
              "2310   what is one of best things about being an anim...           (2310, [design, animation, art, artist])\n",
              "9682                    How to get started in animation?                   (9682, [animation, art, artist])\n",
              "11231  Do I have to live in a big city to do well in ...  (11231, [design, art, artist, graphic-design, ...\n",
              "13484  Would a Graphic Design degree be a feesible op...                     (13484, [graphic-design, art])\n",
              "6058   How should you start in the Graphic Design ind...              (6058, [graphic-design, design, art])\n",
              "16967  How do you get a job in a competitive work field?                        (16967, [photography, art])\n",
              "19275  how do i get my content (animations) out in th...                          (19275, [animation, art])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Professional Id (3): Previous Answered Questions\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>questions_title</th>\n",
              "      <th>question_features</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>11339</th>\n",
              "      <td>What are the different jobs a person can do in Forensic Science?</td>\n",
              "      <td>(11339, [justice, criminal, science, forensic])</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14818</th>\n",
              "      <td>What does a typical work day for a forensic scientist look like?</td>\n",
              "      <td>(14818, [No Tag])</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19077</th>\n",
              "      <td>Is most of your day spent working when being a detective?</td>\n",
              "      <td>(19077, [detective])</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table style=\"display:inline\"><table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>professionals_id_num</th>\n",
              "      <th>professionals_tag_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table style=\"display:inline\">"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Professional Id (3): Recommended Questions: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>questions_title</th>\n",
              "      <th>question_features</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2423</th>\n",
              "      <td>How long does it take to become a Detective?</td>\n",
              "      <td>(2423, [police, law-enforcement, lawyer, crimi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17184</th>\n",
              "      <td>What types of Detectives are there?</td>\n",
              "      <td>(17184, [police, law-enforcement, lawyer, crim...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9778</th>\n",
              "      <td>I want to be a police officer or a police disp...</td>\n",
              "      <td>(9778, [police, police-officer, law-enforcemen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11514</th>\n",
              "      <td>What does an aspiring cop have to look forward...</td>\n",
              "      <td>(11514, [law-enforcement, criminal-justice, po...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17823</th>\n",
              "      <td>What do I need to do to get started on crimina...</td>\n",
              "      <td>(17823, [crime, police, law-enforcement, lawye...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8863</th>\n",
              "      <td>What qualifications are needed to be promoted ...</td>\n",
              "      <td>(8863, [law-enforcement, criminal-justice, pol...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1936</th>\n",
              "      <td>What degrees do you have to have in order to g...</td>\n",
              "      <td>(1936, [law-enforcement, criminal-justice, pol...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17860</th>\n",
              "      <td>What college would you recommend for criminal ...</td>\n",
              "      <td>(17860, [law-enforcement, criminal-justice])</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         questions_title                                  question_features\n",
              "2423        How long does it take to become a Detective?  (2423, [police, law-enforcement, lawyer, crimi...\n",
              "17184                What types of Detectives are there?  (17184, [police, law-enforcement, lawyer, crim...\n",
              "9778   I want to be a police officer or a police disp...  (9778, [police, police-officer, law-enforcemen...\n",
              "11514  What does an aspiring cop have to look forward...  (11514, [law-enforcement, criminal-justice, po...\n",
              "17823  What do I need to do to get started on crimina...  (17823, [crime, police, law-enforcement, lawye...\n",
              "8863   What qualifications are needed to be promoted ...  (8863, [law-enforcement, criminal-justice, pol...\n",
              "1936   What degrees do you have to have in order to g...  (1936, [law-enforcement, criminal-justice, pol...\n",
              "17860  What college would you recommend for criminal ...       (17860, [law-enforcement, criminal-justice])"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mw3z9I5Z-On"
      },
      "source": [
        "# **Now Storing the model checkpoints**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXBT-STkaJM4"
      },
      "source": [
        "import pickle\n",
        "\n",
        "with open('hybrid_recommendation.pickle', 'wb') as fle:\n",
        "    pickle.dump(model, fle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81bgWIr35d9q"
      },
      "source": [
        "# **NOW PREPARING CODE FOR PRODUCTION**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwGgIaWBaJFJ"
      },
      "source": [
        "class CareerVillageDataPreparation:\n",
        "    \"\"\"\n",
        "    Clean and process data CareerVillage Data. \n",
        "    \n",
        "    This class process data in a way that will be useful\n",
        "    for building lightFM dataset. \n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def _assign_unique_id(self, data, id_col_name):\n",
        "        \"\"\"\n",
        "        Generate unique integer id for users, questions and answers\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        data: Dataframe\n",
        "            Pandas Dataframe for Users or Q&A. \n",
        "        id_col_name : String \n",
        "            New integer id's column name.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Dataframe\n",
        "            Updated dataframe containing new id column\n",
        "        \"\"\"\n",
        "        new_dataframe=data.assign(\n",
        "            int_id_col_name=np.arange(len(data))\n",
        "            ).reset_index(drop=True)\n",
        "        return new_dataframe.rename(columns={'int_id_col_name': id_col_name})\n",
        "\n",
        "    def _dropna(self, data, column, axis):\n",
        "        \"\"\"Drop null values from specific column\"\"\"\n",
        "        return data.dropna(column, axis=axis)\n",
        "\n",
        "    def _merge_data(self, left_data, left_key, right_data, right_key, how):\n",
        "        \"\"\"\n",
        "        This function is used for merging two dataframe.\n",
        "        \n",
        "        Parameters\n",
        "        -----------\n",
        "        left_data: Dataframe\n",
        "            Left side dataframe for merge\n",
        "        left_key: String\n",
        "            Left Dataframe merge key\n",
        "        right_data: Dataframe\n",
        "            Right side dataframe for merge\n",
        "        right_key: String\n",
        "            Right Dataframe merge key\n",
        "        how: String\n",
        "            Method of merge (inner, left, right, outer)\n",
        "            \n",
        "        \n",
        "        Returns\n",
        "        --------\n",
        "        Dataframe\n",
        "            A new dataframe merging left and right dataframe\n",
        "        \"\"\"\n",
        "        return left_data.merge(\n",
        "            right_data,\n",
        "            how=how,\n",
        "            left_on=left_key,\n",
        "            right_on=right_key)\n",
        "\n",
        "    def _group_tags(self, data, group_by, tag_column):\n",
        "        \"\"\"Group multiple tags into single rows sepearated by comma\"\"\"\n",
        "        return data.groupby(\n",
        "            [group_by])[tag_column].apply(\n",
        "            ','.join).reset_index()\n",
        "\n",
        "    def _merge_cv_datasets(\n",
        "        self,\n",
        "        professionals,students,\n",
        "        questions,answers,\n",
        "        tags,tag_questions,tag_users, questions_score):\n",
        "        \"\"\"\n",
        "        This function merges all the necessary \n",
        "        CareerVillage dataset in defined way. \n",
        "        \n",
        "        Parameters\n",
        "        ------------\n",
        "        professionals,students,\n",
        "        questions,answers,\n",
        "        tags,tag_questions,\n",
        "        tag_users,\n",
        "        questions_score: Dataframe\n",
        "            Pandas dataframe defined by it's name\n",
        "        \n",
        "        \n",
        "        Returns\n",
        "        ---------\n",
        "        questions, professionals: Dataframe\n",
        "            Updated dataframe after merge\n",
        "        merge: Dataframe\n",
        "            A new datframe after merging answers with questions\n",
        "        \"\"\"\n",
        "        \n",
        "        \n",
        "        # merge tag_questions with tags name\n",
        "        # then group all tags for each question into single rows\n",
        "        tag_question = self._merge_data(\n",
        "            left_data=tag_questions,\n",
        "            left_key='tag_questions_tag_id',\n",
        "            right_data=tags,\n",
        "            right_key='tags_tag_id',\n",
        "            how='inner')\n",
        "        tag_question = self._group_tags(\n",
        "            data=tag_question,\n",
        "            group_by='tag_questions_question_id',\n",
        "            tag_column='tags_tag_name')\n",
        "        \n",
        "        tag_question = tag_question.rename(\n",
        "            columns={'tags_tag_name': 'questions_tag_name'})\n",
        "        \n",
        "        # merge tag_users with tags name\n",
        "        # then group all tags for each user into single rows \n",
        "        # after that rename the tag column name\n",
        "        tags_pro = self._merge_data(\n",
        "            left_data=tag_users,\n",
        "            left_key='tag_users_tag_id',\n",
        "            right_data=tags,\n",
        "            right_key='tags_tag_id',\n",
        "            how='inner')\n",
        "        tags_pro = self._group_tags(\n",
        "            data=tags_pro,\n",
        "            group_by='tag_users_user_id',\n",
        "            tag_column='tags_tag_name')\n",
        "        tags_pro = tags_pro.rename(\n",
        "            columns={'tags_tag_name': 'professionals_tag_name'})\n",
        "        \n",
        "        # merge professionals and questions tags with main merge_dataset \n",
        "        questions = self._merge_data(\n",
        "            left_data=questions,\n",
        "            left_key='questions_id',\n",
        "            right_data=tag_question,\n",
        "            right_key='tag_questions_question_id',\n",
        "            how='left')\n",
        "        professionals = self._merge_data(\n",
        "            left_data=professionals,\n",
        "            left_key='professionals_id',\n",
        "            right_data=tags_pro,\n",
        "            right_key='tag_users_user_id',\n",
        "            how='left')\n",
        "        \n",
        "        # merge questions with scores \n",
        "        questions = self._merge_data(\n",
        "            left_data=questions,\n",
        "            left_key='questions_id',\n",
        "            right_data=questions_score,\n",
        "            right_key='id',\n",
        "            how='left')\n",
        "        \n",
        "        # merge questions with students\n",
        "        questions = self._merge_data(\n",
        "            left_data=questions,\n",
        "            left_key='questions_author_id',\n",
        "            right_data=students,\n",
        "            right_key='students_id',\n",
        "            how='left')\n",
        "        \n",
        "        # merge answers with questions\n",
        "        # then merge professionals and questions score with that\n",
        "        merge = self._merge_data(\n",
        "            left_data=answers,\n",
        "            left_key='answers_question_id',\n",
        "            right_data=questions,\n",
        "            right_key='questions_id',\n",
        "            how='inner')\n",
        "        \n",
        "        merge = self._merge_data(\n",
        "            left_data=merge,\n",
        "            left_key='answers_author_id',\n",
        "            right_data=professionals,\n",
        "            right_key='professionals_id',\n",
        "            how='inner')\n",
        "        \n",
        "        return questions, professionals, merge\n",
        "  \n",
        "    def _drop_duplicates_tags(self, data, col_name):\n",
        "        # drop duplicates tags from each row\n",
        "        return (\n",
        "            data[col_name].str.split(\n",
        "                ',').apply(set).str.join(','))\n",
        "\n",
        "\n",
        "    def _merge_pro_pre_ans_tags(self, professionals, merge):\n",
        "        ########################\n",
        "        # Merge professionals previous answered\n",
        "        # questions tags into professionals tags\n",
        "        ########################\n",
        "        \n",
        "        # yha par professional ny apny prefered ya liked tags sy hat kr bhi kch swaalo k jawab dye hue hongy\n",
        "        # yani agr me datascience ka tag like kra hai to ho skta hai k mene aesy swaal ka ans kra ho jiska tag animation ho. to hum un swaalo k tag professsional\n",
        "        # k liked tags k sth merge kr dengy. \n",
        "\n",
        "        # select professionals answered questions tags\n",
        "        # and stored as a dataframe\n",
        "        professionals_prev_ans_tags = (\n",
        "            merge[['professionals_id', 'questions_tag_name']])\n",
        "        # drop null values from that\n",
        "        professionals_prev_ans_tags = professionals_prev_ans_tags.dropna()\n",
        "        \n",
        "        # because professsionals answers multiple questions,\n",
        "        # we group all of tags of each user into single row\n",
        "        professionals_prev_ans_tags = self._group_tags(\n",
        "            data=professionals_prev_ans_tags,\n",
        "            group_by='professionals_id',\n",
        "            tag_column='questions_tag_name')\n",
        "        \n",
        "        # drop duplicates tags from each professionals rows\n",
        "        professionals_prev_ans_tags['questions_tag_name'] = \\\n",
        "        self._drop_duplicates_tags(\n",
        "            professionals_prev_ans_tags, 'questions_tag_name')\n",
        "        \n",
        "        # finally merge the dataframe with professionals dataframe\n",
        "        professionals = self._merge_data(\n",
        "            left_data=professionals,\n",
        "            left_key='professionals_id',\n",
        "            right_data=professionals_prev_ans_tags,\n",
        "            right_key='professionals_id',\n",
        "            how='left')\n",
        "        \n",
        "        # join professionals tags and their answered tags \n",
        "        # we replace nan values with \"\"\n",
        "        professionals['professional_all_tags'] = (\n",
        "            professionals[['professionals_tag_name',\n",
        "                           'questions_tag_name']].apply(\n",
        "                lambda x: ','.join(x.dropna()),\n",
        "                axis=1))\n",
        "        # yha par hum 2 columns ko aapas me merge kr rhy hain. yani un 2 cols k andarr moujood tags merge ho kr ak hi column me aajae gy. \n",
        "        # remember hum 2 columns ko merge join() operation ya function sy krty hain. merge() hum 2 datasets k lye use krty hain. \n",
        "        return professionals\n",
        "\n",
        "    def prepare(\n",
        "        self,\n",
        "        professionals,students,\n",
        "        questions,answers,\n",
        "        tags,tag_questions,tag_users, questions_score):\n",
        "        \n",
        "        \"\"\"\n",
        "        This function clean and process \n",
        "        CareerVillage Data sets. \n",
        "        \"\"\"\n",
        "        \n",
        "        # assign unique integer id\n",
        "        professionals = self._assign_unique_id(\n",
        "            professionals, 'professionals_id_num')\n",
        "        students = self._assign_unique_id(\n",
        "            students, 'students_id_num')\n",
        "        questions = self._assign_unique_id(\n",
        "            questions, 'questions_id_num')\n",
        "        answers = self._assign_unique_id(\n",
        "            answers, 'answers_id_num')\n",
        "        \n",
        "        # just dropna from tags \n",
        "        tags = tags.dropna()\n",
        "        tags['tags_tag_name'] = tags['tags_tag_name'].str.replace(\n",
        "            '#', '')\n",
        "        \n",
        "        \n",
        "        # merge necessary datasets\n",
        "        df_questions, df_professionals, df_merge = self._merge_cv_datasets(\n",
        "            professionals,students,\n",
        "            questions,answers,\n",
        "            tags,tag_questions,tag_users,\n",
        "            questions_score)\n",
        "        \n",
        "        #######################\n",
        "        # Generate some features for calculates weights\n",
        "        # that will use with interaction matrix\n",
        "        #######################\n",
        "        df_merge['num_ans_per_ques'] = df_merge.groupby(\n",
        "            ['questions_id'])['answers_id'].transform('count')\n",
        "        # ak question id par jitny logo no ans kiye hongy un sb ki id count kro yani total answers per question count kro.\n",
        "\n",
        "        # merge pro previoius answered question tags with pro tags \n",
        "        df_professionals = self._merge_pro_pre_ans_tags(\n",
        "            df_professionals, df_merge)\n",
        "        \n",
        "        # some more pre-processing \n",
        "        # handling null values \n",
        "        df_questions['score'] = df_questions['score'].fillna(0)\n",
        "        df_questions['score'] = df_questions['score'].astype(int)\n",
        "        df_questions['questions_tag_name'] = \\\n",
        "        df_questions['questions_tag_name'].fillna('No Tag')\n",
        "        \n",
        "        # remove duplicates tags from each questions \n",
        "        df_questions['questions_tag_name'] = \\\n",
        "        df_questions['questions_tag_name'].str.split(\n",
        "            ',').apply(set).str.join(',')\n",
        "\n",
        "        # fill nan with 'No Tag' if any \n",
        "        df_professionals['professional_all_tags'] = \\\n",
        "        df_professionals['professional_all_tags'].fillna(\n",
        "            'No Tag')\n",
        "        # replace \"\" with \"No Tag\", because previously we replace nan with \"\"\n",
        "        df_professionals['professional_all_tags'] = \\\n",
        "        df_professionals['professional_all_tags'].replace(\n",
        "            '', 'No Tag')\n",
        "        \n",
        "        df_professionals['professionals_location'] = \\\n",
        "        df_professionals['professionals_location'].fillna(\n",
        "            'No Location')\n",
        "        \n",
        "        df_professionals['professionals_industry'] = \\\n",
        "        df_professionals['professionals_industry'].fillna(\n",
        "            'No Industry')\n",
        "\n",
        "        # remove duplicates tags from each professionals\n",
        "        df_professionals['professional_all_tags'] = \\\n",
        "        df_professionals['professional_all_tags'].str.split(\n",
        "            ',').apply(set).str.join(',')\n",
        "\n",
        "        # remove some null values from df_merge\n",
        "        df_merge['num_ans_per_ques']  = \\\n",
        "        df_merge['num_ans_per_ques'].fillna(0)\n",
        "        \n",
        "        return df_questions, df_professionals, df_merge"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9eSL9R5a6Em"
      },
      "source": [
        "**Building Data for LightFM Class:** From step 2 we already know that lightfm library except data in a very specific and elligent way. LightFM data format is already discussed in step 2. Feel free to read that. Now we are building a class that will be put all of dataset building puzzle in a specific class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ffxp4zZCaJBg"
      },
      "source": [
        "class LightFMDataPrep:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "    def create_features(self, dataframe, features_name, id_col_name):\n",
        "        \"\"\"\n",
        "        Generate features that will be ready for feeding into lightfm\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        dataframe: Dataframe\n",
        "            Pandas Dataframe which contains features\n",
        "        features_name : List\n",
        "            List of feature columns name avaiable in dataframe\n",
        "        id_col_name: String\n",
        "            Column name which contains id of the question or\n",
        "            answer that the features will map to.\n",
        "            There are two possible values for this variable.\n",
        "            1. questions_id_num\n",
        "            2. professionals_id_num\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Pandas Series\n",
        "            A pandas series containing process features\n",
        "            that are ready for feed into lightfm.\n",
        "            The format of each value\n",
        "            will be (user_id, ['feature_1', 'feature_2', 'feature_3'])\n",
        "            Ex. -> (1, ['military', 'army', '5'])\n",
        "        \"\"\"\n",
        "\n",
        "        features = dataframe[features_name].apply(\n",
        "            lambda x: ','.join(x.map(str)), axis=1)\n",
        "        features = features.str.split(',')\n",
        "        features = list(zip(dataframe[id_col_name], features))\n",
        "        return features\n",
        "\n",
        "\n",
        "\n",
        "    def generate_feature_list(self, dataframe, features_name):\n",
        "        \"\"\"\n",
        "        Generate features list for mapping \n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        dataframe: Dataframe\n",
        "            Pandas Dataframe for Users or Q&A. \n",
        "        features_name : List\n",
        "            List of feature columns name avaiable in dataframe. \n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        List of all features for mapping \n",
        "        \"\"\"\n",
        "        features = dataframe[features_name].apply(\n",
        "            lambda x: ','.join(x.map(str)), axis=1)\n",
        "        features = features.str.split(',')\n",
        "        features = features.apply(pd.Series).stack().reset_index(drop=True)\n",
        "        return features\n",
        "    \n",
        "    def create_data(self, questions, professionals, merge):\n",
        "        question_feature_list = self.generate_feature_list(\n",
        "            questions,\n",
        "            ['questions_tag_name'])\n",
        "\n",
        "        professional_feature_list = self.generate_feature_list(\n",
        "            professionals,\n",
        "            ['professional_all_tags'])\n",
        "        \n",
        "        merge['total_weights'] = 1 / (\n",
        "            merge['num_ans_per_ques'])\n",
        "        \n",
        "        # creating features for feeding into lightfm \n",
        "        questions['question_features'] = self.create_features(\n",
        "            questions, ['questions_tag_name'], \n",
        "            'questions_id_num')\n",
        "        \n",
        "        # question_features ka mtlb hai k user ki id or usky tags\n",
        "\n",
        "        professionals['professional_features'] = self.create_features(\n",
        "            professionals,\n",
        "            ['professional_all_tags'],\n",
        "            'professionals_id_num')\n",
        "        \n",
        "        # professional_features ka mtlb hai k professional ki id or usky tags\n",
        "        \n",
        "        return question_feature_list,\\\n",
        "    professional_feature_list,merge,questions,professionals\n",
        "        \n",
        "    def fit(self, questions, professionals, merge):\n",
        "        ########################\n",
        "        # Dataset building for lightfm\n",
        "        ########################\n",
        "        question_feature_list, \\\n",
        "        professional_feature_list,\\\n",
        "        merge,questions,professionals = \\\n",
        "        self.create_data(questions, professionals, merge)\n",
        "        \n",
        "        \n",
        "        # define our dataset variable\n",
        "        # then we feed unique professionals and questions ids\n",
        "        # and item and professional feature list\n",
        "        # this will create lightfm internel mapping\n",
        "        dataset = Dataset()\n",
        "        dataset.fit(\n",
        "            set(professionals['professionals_id_num']), \n",
        "            set(questions['questions_id_num']),\n",
        "            item_features=question_feature_list, \n",
        "            user_features=professional_feature_list)\n",
        "\n",
        "\n",
        "        # now we are building interactions\n",
        "        # matrix between professionals and quesitons\n",
        "        # we are passing professional and questions id as a tuple\n",
        "        # e.g -> pd.Series((pro_id, question_id), (pro_id, questin_id))\n",
        "        # then we use lightfm build in method for building interactions matrix\n",
        "        merge['author_question_id_tuple'] = list(zip(\n",
        "            merge.professionals_id_num,\n",
        "            merge.questions_id_num,\n",
        "            merge.total_weights))\n",
        "\n",
        "        interactions, weights = dataset.build_interactions(\n",
        "            merge['author_question_id_tuple'])\n",
        "\n",
        "\n",
        "\n",
        "        # now we are building our questions and\n",
        "        # professionals features\n",
        "        # in a way that lightfm understand.\n",
        "        # we are using lightfm build in method for building\n",
        "        # questions and professionals features \n",
        "        questions_features = dataset.build_item_features(\n",
        "            questions['question_features'])\n",
        "\n",
        "        professional_features = dataset.build_user_features(\n",
        "            professionals['professional_features'])\n",
        "        \n",
        "        return interactions,\\\n",
        "    weights,questions_features,professional_features\n",
        "        "
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmEQDo5FeUBD"
      },
      "source": [
        "**Train Model Class:** In step 2, we saw how we build and train our model. Now we are going to put those all together in TrainLightFM class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGQblb7nrRa5"
      },
      "source": [
        "class TrainLightFM:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "        \n",
        "    def train_test_split(self, interactions, weights):\n",
        "        train_interactions, test_interactions = \\\n",
        "        cross_validation.random_train_test_split(\n",
        "            interactions, \n",
        "            random_state=np.random.RandomState(2019))\n",
        "        \n",
        "        train_weights, test_weights = \\\n",
        "        cross_validation.random_train_test_split(\n",
        "            weights, \n",
        "            random_state=np.random.RandomState(2019))\n",
        "        return train_interactions,\\\n",
        "    test_interactions, train_weights, test_weights\n",
        "    \n",
        "    def fit(self, interactions, weights,\n",
        "            questions_features, professional_features,\n",
        "            cross_validation=False,no_components=150,\n",
        "            learning_rate=0.05,\n",
        "            loss='warp',\n",
        "            random_state=2019,\n",
        "            verbose=True,\n",
        "            num_threads=4, epochs=5):\n",
        "        ################################\n",
        "        # Model building part\n",
        "        ################################\n",
        "\n",
        "        # define lightfm model by specifying hyper-parametre\n",
        "        # then fit the model with ineteractions matrix,\n",
        "        # item and user features\n",
        "        \n",
        "        model = LightFM(\n",
        "            no_components,\n",
        "            learning_rate,\n",
        "            loss=loss,\n",
        "            random_state=random_state)\n",
        "        model.fit(\n",
        "            interactions,\n",
        "            item_features=questions_features,\n",
        "            user_features=professional_features, sample_weight=weights,\n",
        "            epochs=epochs, num_threads=num_threads, verbose=verbose)\n",
        "        \n",
        "        return model"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1uRR9r6fUvK"
      },
      "source": [
        "**Recommendations classs:** Now we are going to build a class for making recommendations. This will make easy for making recommendations in djono api. This recommendations class build with extra features. You can use this for general prediction by giving professionals ids and questions features. It has another features that let's choose questions from range of two dates and make recommendation from those questions.\n",
        "\n",
        "This is useful because those professionals that choose email frequency lavel as \"weekly\" or \"daily\", we can select questions from a week and then recommend those questions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_Vzr3e2bQDf"
      },
      "source": [
        "class LightFMRecommendations:\n",
        "    \"\"\"\n",
        "    Make prediction given model and professional ids\n",
        "    \"\"\"\n",
        "    def __init__(self, lightfm_model,\n",
        "                 professionals_features,\n",
        "                 questions_features,\n",
        "                 questions,professionals,merge):\n",
        "        self.model = lightfm_model\n",
        "        self.professionals_features = professionals_features\n",
        "        self.questions_features = questions_features\n",
        "        self.questions = questions\n",
        "        self.professionals = professionals\n",
        "        self.merge = merge\n",
        "        \n",
        "    def previous_answered_questions(self, professionals_id):\n",
        "        previous_q_id_num = (\n",
        "            self.merge.loc[\\\n",
        "                self.merge['professionals_id_num'] == \\\n",
        "                professionals_id]['questions_id_num'])\n",
        "        \n",
        "        previous_answered_questions = self.questions.loc[\\\n",
        "            self.questions['questions_id_num'].isin(\n",
        "            previous_q_id_num)]\n",
        "        return previous_answered_questions\n",
        "        \n",
        "    \n",
        "    def _filter_question_by_pro(self, professionals_id):\n",
        "        \"\"\"Drop questions that professional already answer\"\"\"\n",
        "        previous_answered_questions = \\\n",
        "        self.previous_answered_questions(professionals_id)\n",
        "        \n",
        "        discard_qu_id = \\\n",
        "        previous_answered_questions['questions_id_num'].values.tolist()\n",
        "        \n",
        "        questions_for_prediction = \\\n",
        "        self.questions.loc[~self.questions['questions_id_num'].isin(discard_qu_id)]\n",
        "        \n",
        "        return questions_for_prediction\n",
        "    \n",
        "    def _filter_question_by_date(self, questions, start_date, end_date):\n",
        "        mask = \\\n",
        "        (questions['questions_date_added'] > start_date) & \\\n",
        "        (questions['questions_date_added'] <= end_date)\n",
        "        \n",
        "        return questions.loc[mask]\n",
        "        \n",
        "    \n",
        "    def recommend_by_pro_id_general(self,\n",
        "                                    professional_id,\n",
        "                                    num_prediction=8):\n",
        "        questions_for_prediction = self._filter_question_by_pro(professional_id)\n",
        "        score = self.model.predict(\n",
        "            professional_id,\n",
        "            questions_for_prediction['questions_id_num'].values.tolist(), \n",
        "            item_features=self.questions_features,\n",
        "            user_features=self.professionals_features)\n",
        "        \n",
        "        questions_for_prediction['recommendation_score'] = score\n",
        "        questions_for_prediction = questions_for_prediction.sort_values(\n",
        "            by='recommendation_score', ascending=False)[:num_prediction]\n",
        "        return questions_for_prediction\n",
        "    \n",
        "    def recommend_by_pro_id_frequency_date_range(self,\n",
        "                                                 professional_id,\n",
        "                                                 start_date,\n",
        "                                                 end_date,\n",
        "                                                 num_prediction=8):\n",
        "        questions_for_prediction = \\\n",
        "        self._filter_question_by_pro(professional_id)\n",
        "        \n",
        "        start_date = datetime.datetime.strptime(start_date, '%Y-%m-%d')\n",
        "        end_date = datetime.datetime.strptime(end_date, '%Y-%m-%d')\n",
        "        \n",
        "        questions_for_prediction = self._filter_question_by_date(\n",
        "            questions_for_prediction, start_date, end_date)\n",
        "        \n",
        "        score = self.model.predict(\n",
        "            professional_id,\n",
        "            questions_for_prediction['questions_id_num'].values.tolist(), \n",
        "            item_features=self.questions_features,\n",
        "            user_features=self.professionals_features)\n",
        "        \n",
        "        questions_for_prediction['recommendation_score'] = score\n",
        "        questions_for_prediction = questions_for_prediction.sort_values(\n",
        "            by='recommendation_score', ascending=False)[:num_prediction]\n",
        "        return questions_for_prediction"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcI63ES6jk7S"
      },
      "source": [
        "**Put it all together:** Now we defined all our important class file. Let's use each of these class and build our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uojA1lVGbP-9",
        "outputId": "7e098349-8b8e-446f-930d-02a516eaa821",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "from lightfm import LightFM\n",
        "from lightfm.data import Dataset\n",
        "import datetime\n",
        "\n",
        "# instiate all class instance\n",
        "cv_data_prep = CareerVillageDataPreparation()\n",
        "light_fm_data_prep = LightFMDataPrep()\n",
        "train_lightfm = TrainLightFM()\n",
        "\n",
        "# process raw data\n",
        "df_questions_p, df_professionals_p, df_merge_p = \\\n",
        "cv_data_prep.prepare(\n",
        "    df_professionals,df_students,\n",
        "    df_questions,df_answers,\n",
        "    df_tags,df_tag_questions,df_tag_users,\n",
        "    df_question_scores)\n",
        "\n",
        "\n",
        "# prepare data for lightfm \n",
        "interactions, weights, \\\n",
        "questions_features, professional_features = \\\n",
        "light_fm_data_prep.fit(\n",
        "    df_questions_p, df_professionals_p, df_merge_p)\n",
        "\n",
        "\n",
        "# finally build and trian our model\n",
        "# model = train_lightfm.fit(interactions,\n",
        "#                           weights,\n",
        "#                           questions_features,\n",
        "#                           professional_features)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-fb9c88e9cb84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mdf_questions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf_answers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mdf_tags\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf_tag_questions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf_tag_users\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     df_question_scores)\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-35-4a80078a61b2>\u001b[0m in \u001b[0;36mprepare\u001b[0;34m(self, professionals, students, questions, answers, tags, tag_questions, tag_users, questions_score)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0;31m# merge pro previoius answered question tags with pro tags\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m         df_professionals = self._merge_pro_pre_ans_tags(\n\u001b[0;32m--> 278\u001b[0;31m             df_professionals, df_merge)\n\u001b[0m\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0;31m# some more pre-processing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-35-4a80078a61b2>\u001b[0m in \u001b[0;36m_merge_pro_pre_ans_tags\u001b[0;34m(self, professionals, merge)\u001b[0m\n\u001b[1;32m    225\u001b[0m         professionals['professional_all_tags'] = (\n\u001b[1;32m    226\u001b[0m             professionals[['professionals_tag_name',\n\u001b[0;32m--> 227\u001b[0;31m                            'questions_tag_name']].apply(\n\u001b[0m\u001b[1;32m    228\u001b[0m                 \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m','\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m                 axis=1))\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2906\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2907\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2908\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2910\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1252\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1254\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1255\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1296\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmissing\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m                 \u001b[0maxis_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1298\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1300\u001b[0m             \u001b[0;31m# We (temporarily) allow for some missing keys with .loc, except in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['professionals_tag_name', 'questions_tag_name'], dtype='object')] are in the [columns]\""
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oc5b3siGkttB"
      },
      "source": [
        "Awesome! Do you see, how easy it was for building our model. We can surely apply this idea when putting the model into production. Now we are going to see some real recommendations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJixzOBNbP6T",
        "outputId": "4584c0c6-67c9-4745-f76f-ee0aaec98e97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "source": [
        "# define our recommender class\n",
        "lightfm_recommendations = LightFMRecommendations(\n",
        "    model,\n",
        "    professional_features,questions_features,\n",
        "    df_questions_p, df_professionals_p, df_merge_p)\n",
        "\n",
        "# let's what our model predict for user id 3\n",
        "print(\"Recommendation for professional: \" + str(3))\n",
        "display(lightfm_recommendations.recommend_by_pro_id_general(99)[:8])"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-67fae825cc39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprofessional_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mquestions_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     df_questions_p, df_professionals_p, df_merge_p)\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# let's what our model predict for user id 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df_questions_p' is not defined"
          ]
        }
      ]
    }
  ]
}